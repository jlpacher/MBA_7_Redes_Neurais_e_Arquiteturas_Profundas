{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo III - Arquiteturas de CNNS e treinamento de redes profundas</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 1 - Exercícios Essenciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 1)\n",
    "\n",
    "Considere as funções de custo: Perda Quadrática (MSE), Erro Absoluto (MAE), Perda 0-1, Perda Hinge/SVM, Entropia Cruzada. Para referência veja a definição da Perda 0-1 e Hinge, não vistas em aula, abaixo. Pesquise mais sobre essas caso necessário\n",
    "\n",
    "*. Perda 0-1\n",
    "\n",
    "$$\\frac{1}{N} \\sum_{i=1}^N \n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t0  & \\mbox{if } y_i = \\hat{y}_i \\\\\n",
    "\t\t1 & \\mbox{if } y_i \\neq \\hat{y}_i \n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "*. Perda SVM/Hinge\n",
    " \n",
    "$$\\frac{1}{N} \\sum_{i=1}^N \\max(0, 1- y^{h}_i\\cdot f(x_i)),$$\n",
    "essa função considera que as classes são -1 e 1, sendo $f(x_i)=\\hat{y}_i^{h}$ um valor de saída considerando valores negativos (os quais gerarão classificação para a classe -1) e positivos (classificação para a classe 1). Portanto será preciso adaptar as classes do problema e a  saída $\\hat{y}^{h}$ para esse cenário da seguinte forma:\n",
    "* $y^{h} \\in \\{-1,1\\}$, e\n",
    "* $\\hat{y}^{h} = 2\\cdot(\\hat{y}-0.5)$,\n",
    "sendo $\\hat{y}$ a probabilidade de uma instância pertencer à classe positiva (1).\n",
    "\n",
    "Para um determinado problema, como escolher qual delas utilizar no treinamento de uma rede neural?\n",
    "\n",
    "(a) Na dúvida escolher sempre a entropia cruzada, pois é a mais popular e considerada um padrão na literatura da área de redes neurais<br>\n",
    "(b) É necessário considerar um subconjunto pequeno de exemplos e sempre testar todas as funções de custo disponíveis, só assim é possível ter certeza de que estaremos selecionando a função mais adequada para o problema em mãos<br>\n",
    "<font color='red'>(c) Avaliar o problema em termos de suas saídas e os valores possíveis para a função de custo, selecionando para realizar experimentos aquelas que mais se adequem ao problema e seja conveniente para realizar otimização baseada em gradiente</font><br>\n",
    "(d) Em geral, a entropia cruzada deve ser utilizada para problemas de classificação, e a perda quadrática para problemas de regressão, não sendo necessário investigar outras funções de custo pois são mais relevantes outros parâmetros como a taxa de aprendizado e o tamanho do batch<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função de custo ou perda deve ser escolhida analisando se forma uma região convexa, ou seja, se é diferenciável para que possa-se buscar o mínimo do gradiente.<br>\n",
    "Idealmente deve ser suave e produzir um gradiente convexo.<br>\n",
    "As funções mais comuns são o MSE para valores contínuos e a cross_entropy para probabilidades.<br>\n",
    "a-Entropia cruzada não é indicada para regressão.<br>\n",
    "b-muito difícil testar todas as funções de custo (existem muitas funções).<br>\n",
    "d.NLP por exemplo tem função de custo específica, ou seja, depende do problema existe uma função de custo mais indicada.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Exercício 2)\n",
    "\n",
    "Considerando as funções de perda: entropia cruzada categórica e perda quadrática, qual é o valor das perdas para um exemplo arbitrário no caso o modelo considere as classes equiprováveis numa tarefa de classificação de 5 classes?\n",
    "\n",
    "<font color='red'> (a) Entropia Cruzada = 1.6; Quadrática = 0.8</font><br>\n",
    " (b) Entropia Cruzada = 2.3; Quadrática = 0.8<br>\n",
    " (c) Entropia Cruzada = 1.6; Quadrática = 0.16<br>\n",
    " (d) Entropia Cruzada = 0.32; Quadrática = 0.8<br>\n",
    "  \n",
    "DICA: compare dois vetores de probabilidade, um com a classe real em *one-hot-encoding* e o outro exemplificando o caso de classes equiprováveis.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "JmVBm5CByqqM",
    "outputId": "5d912e29-5f38-4038-f886-8b7b1ceee008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6094329124466003\n",
      "0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "y = np.array([.0, .0, .0, .0, 1.0])        # vetor de um classificador com 5 classes (classes reais)\n",
    "yh = np.array([0.2, 0.2, 0.2, 0.2, 0.2])   # vetor de inicialização com probabilidades aleatórias (estimador)\n",
    "\n",
    "loss_ec = -np.sum((y*np.log(yh+.000001)))  # cálculo da perda para a entropia cruzada - perda inicial aleatória\n",
    "loss_qu = np.sum(np.power((y-yh),2))       # cálculo da perda quadrática - perda inicial aleatória\n",
    "print(loss_ec)\n",
    "print(loss_qu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na média, numa inicialização aleatória, teríamos um classificador gerando um vetor de probabilidade com a distribuição aproximadamente uniforme, ou seja, todos os valores 0.2=1/5. Computando a entropia cruzada categórica, temos apenas o -log do valor predito para a classe verdadeira, enquanto que na quadrática, a soma dos erros cometidos ao longo do vetor.\n",
    "\n",
    "Perda quadrática é diferente de perda quadrática média."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6exl-MrVyqqT"
   },
   "source": [
    "---\n",
    "### Exercício 3)\n",
    "\n",
    "Sobre os métodos de otimização, o que podemos dizer quando comparamos SGD e Adam?\n",
    "\n",
    "<font color='red'> (a) Ambos realizam atualização iterativa dos parâmetros usando o gradiente, mas o Adam utiliza também o segundo momento do gradiente como ponderação</font><br>\n",
    " (b) O Adam pode ser considerado um caso particular do SGD, sendo ambos algoritmos idênticos se usado SGD com Momentum e atrito de 0,99.<br>\n",
    " (c) Ambos realizam atualização iterativa dos parâmetros usando o gradiente, mas apenas SGD permite decaimento da taxa de aprendizado <br>\n",
    " (d) O Adam sempre obterá resultados melhores do que o SGD para qualquer rede neural profunda<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O SGD utiliza o gradiente, enquanto o Adam computa o segundo momento como forma de ponderar a magnitude do passo. <br>\n",
    "As outras alternativas são inválidas porque: Adam utiliza uma estratégia similar, mas não igual ao momentum, e também possui um tipo de taxa de aprendizado adaptativa; Adam também permite decaimento da taxa de aprendizado; finalmente, ainda que Adam seja um algoritmo de otimização mais sofisticado, não é possível dizer que um algoritmo de otimização será sempre melhor, em particular para cenários complexos. Note por exemplo que muitos modelos do estado da arte são treinados com SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfnm0YgLyqqU"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 4)\n",
    "\n",
    "Dentre as alternativas, escolha a prática válida mais relevante ao projetar o treinamento de redes profundas\n",
    "\n",
    "(a) Inicializar todos os pesos com valores aleatórios e utilizar o maior número de instâncias possíveis no treinamento, garantindo que os hiperparâmetros com valor padrão obterão bons resultados<br>\n",
    "(b) Utilizar sempre a função de custo entropia cruzada, para a qual é recomendado o uso do otimizador Adam e taxa de aprendizado com decaimento. Definir a melhor taxa de decaimento de forma a minimizar a diferença entre o custo de treinamento e validação<br>\n",
    "<font color='red'>(c) Utilizar conjunto pequeno de instâncias para busca inicial de hiperparâmetros como: otimizador, taxa de aprendizado, momentum e tamanho de batch, e depois refinar a busca num conjunto maior com base em métricas obtidas nos conjuntos de validação e treinamento</font><br>\n",
    "(d) Rezar para Yan LeCun, Yoshua Bengio, Geoffrey Hinton e Kunihiko Fukushima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem sempre os valores padrão serão bons hiperparâmetros. Ainda que algumas escolhas sejam populares (como uso de Adam e Entropia Cruzada), o melhor é sempre realizar uma busca, ainda que grosseira com poucos dados, por parâmetros que se ajustem à arquitetura projetada.\n",
    "\n",
    "Tentar overfittar com um conjunto pequeno de dados; se não overfittar tem alguma coisa de errado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6VfUMk8yqqW"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 5)\n",
    "\n",
    "Qual a principal diferença das arquiteturas VGGNet, Inception e Residual Network com relação à suas camadas convolucionais?\n",
    "\n",
    "(a) A VGGNet possui camadas convolucionais com filtros de mesmo tamanho $3\\times3$, enquanto as outras arquiteturas, Inception e ResNet aplicam filtros $5\\times5$ ou com concatenação de mapas de ativação ao longo da rede<br>\n",
    "(b) A rede Inception permite treinamento com maior número de camadas quanto comparada à VGGNet, que por sua vez permite treinamento com maior número de camadas quanto comparada à ResNet <br>\n",
    "(c) A VGGNet possui camadas convolucionais sequenciais, eventualmente seguidas de MaxPooling, enquanto a ResNet computa mapas de ativação de com diferentes filtros, concatenando-os, e a Inception possui um módulo do tipo banco de filtros, que permite saltar para camadas futuras, facilitando o treinamento com mais camadas<br>\n",
    "<font color='red'>(d) A VGGNet possui camadas convolucionais sequenciais, enquanto Inception possui camadas convolucionais paralelas, e ResNet tem mapas de ativação que desviam da lógica sequencial e pulam camadas</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sua principal diferença é o fluxo durante a rede, sendo a VGG sequencial e as outras duas cujas ativações dão saltos (ResNet) ou possuem paralelismo (Inception). <br>\n",
    "\n",
    "Alternativa (a) está errada pois ResNet não aplica filtros de tamanho maior do que 5x5, nem realiza concatenação de mapas de ativação (mas sim a soma); (b) é inválida pois a ResNet permite treinar com mais camadas do que a VGG; (c) está errada pois Inception não possui saltos nas camadas, nem ResNet possui concatenação de mapas. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 6)\n",
    "\n",
    "Utilizando a biblioteca Keras, investige os hiperparâmetros relacionados a learning rate na base de dados Boston Housing. Carregue a base de dados e normalize os atributos com z-score. Crie uma rede com camadas densas: 16, 8 e 1 (de saída), todas com ativação `relu`, função de custo `mse`, medindo também a `mae` como avaliação adicional.\n",
    "\n",
    "Iremos investigar o uso de decaimento de learning rate, a partir de um valor inicial estabelecido. Para isso vamos usar um conjunto de validação de 20% retirado a partir do conjunto de testes, e repetir 5 vezes, cada vez utilizando uma semente, de 1 até 5, conforme código base abaixo.\n",
    "\n",
    "Treine por 25 épocas com batchsize 32 e com o otimizador Adam, 2 arquiteturas diferentes:\n",
    "\n",
    "*A*. Uso dos parâmetros padrão<br>\n",
    "*B*. Iniciando com learning rate 0.01 e decaimento exponencial de 0.05 a partir da época 5\n",
    "\n",
    "Posteriormente, treine os dois modelos, porém agora com o conjunto de treinamento completo e avalie no conjunto de teste.\n",
    "\n",
    "Considerando a média dos valores de erro (MSE e MAE) obtidos na validação arredondados para um número inteiro (ou seja, sem considerar as casas decimais), e posteriormente os mesmos erros quando treinado com o conjunto completo e avaliados no teste:\n",
    "\n",
    "(a) B obteve menores valores de erro (MSE e MAE) do que A na validação, B também tem MAE menor do que A no teste, mas ambos foram similares no MSE do teste<br>\n",
    "(b) B obteve menores valores de erro (MSE e MAE) do que A na validação e no teste<br>\n",
    "(c) A obteve valores de erro MAE menores do que B, mas valores MSE maiores do que B na validação e no teste.<br>\n",
    "(d) A obteve valores de erro MAE e MSE similares com B na validação e no teste<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K5Owfr6GyqqY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "mean = x_train.mean(axis=0)\n",
    "std = x_train.std(axis=0)\n",
    "\n",
    "# normalization with z-score\n",
    "x_train -= mean  # operator subtract and\n",
    "x_train /= std   # operator divide and\n",
    "\n",
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (x_train.shape[1],)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dnn(input_shape):\n",
    "    \"\"\"\n",
    "    Função para a arquitetura de 3 camadas densas\n",
    "    Entrada: dimensão dos dados\n",
    "    Saída: modelo de previsão\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(16, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(8, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1, activation=\"relu\"))\n",
    "    return model\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Função para o decaimento da taxa de aprendizado com a época\n",
    "    Entrada: época e taxa de aprendizado inicial\n",
    "    Saída: taxa de aprendizado\n",
    "    \"\"\"\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return np.round(lr * tf.math.exp(-0.05),4)\n",
    "    \n",
    "callbacklr = keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1\n",
      "Seed 2\n",
      "Seed 3\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001497EEB7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001497E955160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Seed 4\n",
      "Seed 5\n",
      "Validacao\tMSE\tMAE\n",
      "Default LR\t110\t8\n",
      "Scheduling\t16\t3\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "# arrays para conter os erros\n",
    "mses = []\n",
    "maes = []\n",
    "\n",
    "# para cada semente\n",
    "for sd in range(1,6):\n",
    "    x_trains, x_val, y_trains, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=sd)\n",
    "    input_shape = (x_trains.shape[1],)\n",
    "    print(\"Seed\", sd)\n",
    "    seed(sd)\n",
    "    set_seed(sd)\n",
    "    \n",
    "    # modelo A: Hiperparâmetros com valor padrão\n",
    "    modelA = my_dnn(input_shape)\n",
    "    modelA.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=['mae'])\n",
    "    modelA.fit(x_trains, y_trains, epochs=epochs, batch_size=32, verbose=0)\n",
    "    \n",
    "    # modelo B: Iniciando com learning rate 0.01 e decaimento exponencial de 0.05 a partir da época 5\n",
    "    modelB = my_dnn(input_shape)\n",
    "    modelB.compile(optimizer=keras.optimizers.Adam(0.01), loss='mse', metrics=['mae'])\n",
    "    modelB.fit(x_trains, y_trains, epochs=epochs, batch_size=32, callbacks=[callbacklr], verbose=0)\n",
    "    \n",
    "    #avaliar na validacao\n",
    "    score = modelA.evaluate(x_val, y_val, verbose = 0)\n",
    "    mses.append(score[0])\n",
    "    maes.append(score[1])\n",
    "    \n",
    "    score = modelB.evaluate(x_val, y_val, verbose = 0)\n",
    "    mses.append(score[0])\n",
    "    maes.append(score[1])\n",
    "    \n",
    "# converte métricas em array e refaz o formato para que fiquem 5 execucoes (linhas) e 2 modelos (A e B)\n",
    "mses = np.array(mses)        \n",
    "mses = mses.reshape((5,2))\n",
    "\n",
    "maes = np.array(maes)        \n",
    "maes = maes.reshape((5,2))\n",
    "\n",
    "mean_mses = np.mean(mses, axis=0)\n",
    "mean_maes = np.mean(maes, axis=0)\n",
    "print('Validacao\\tMSE\\tMAE')\n",
    "for met,mse1,mae1 in zip(['Default LR', 'Scheduling'], mean_mses, mean_maes):\n",
    "       print(\"%s\\t%.0f\\t%.0f\" % (met, mse1,mae1))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste            MSE             MAE\n",
      "Default LR [51.42583465576172, 5.763203144073486]\n",
      "Scheduling [22.39095687866211, 3.2574920654296875]\n"
     ]
    }
   ],
   "source": [
    "# avalia novamentem agora no conjunto de teste!\n",
    "epochs = 25\n",
    "seed(sd)\n",
    "set_seed(sd)\n",
    "modelA = my_dnn((x_train.shape[1],))\n",
    "modelA.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=['mae'])\n",
    "modelA.fit(x_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "    \n",
    "seed(sd)\n",
    "set_seed(sd)\n",
    "modelB = my_dnn((x_train.shape[1],))\n",
    "modelB.compile(optimizer=keras.optimizers.Adam(0.01), loss='mse', metrics=['mae'])\n",
    "modelB.fit(x_train, y_train, epochs=epochs, batch_size=32, callbacks=[callbacklr], verbose=0)\n",
    "\n",
    "print('Teste            MSE             MAE')\n",
    "\n",
    "score = modelA.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Default LR', score)\n",
    "    \n",
    "score = modelB.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Scheduling', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_F2ODAmyqq4"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 7)\n",
    "\n",
    "Utilizando ainda a biblioteca Keras, investige o impacto do uso de parâmetros padrão de batchsize na base de dados Boston Housing, agora utilizando a mesma arquitetura da atividade anterior, com otimizador Adam, iniciando com learning rate 0.02 e decaimento exponencial de 0.05 a partir da época 6.\n",
    "\n",
    "Investige valores de batch = 2, 4, 8, 16, 32, 64, 128 e 256 executando por 15 épocas.\n",
    "\n",
    "Para isso vamos usar um conjunto de validação de 20% retirado a partir do conjunto de **treino**, e repetir 5 vezes, cada vez utilizando uma semente, de 1 até 5, conforme código base abaixo.\n",
    "\n",
    "Após o treinamento, avalie MSE nos dados de validação e imprima a média do MSE obtido para os diferentes valores de batchsize.\n",
    "\n",
    "Quais foram os dois piores e os dois melhores valores de tamanho de batch em termos do MSE de validação?\n",
    "\n",
    "(a) Piores: 128 e 256; Melhores: 8 e 16<br>\n",
    "(b) Piores: 16 e 64; Melhores: 32 e 64<br>\n",
    "(c) Piores: 2 e 4; Melhores: 8 e 16<br>\n",
    "(d) Piores: 2 e 256; Melhores: 16 e 32<br>\n",
    "\n",
    "OBS: a aleatoriedade do processo pode gerar alguma variação de resultado, caso seja isso tente escolher a alternativa mais coerente, ou rodar algumas vezes para ver se há alternativa válida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1: 2 4 8 16 32 64 128 256 \n",
      "Seed 2: 2 4 8 16 32 64 128 256 \n",
      "Seed 3: 2 4 8 16 32 64 128 256 \n",
      "Seed 4: 2 4 8 16 32 64 128 256 \n",
      "Seed 5: 2 4 8 16 32 64 128 256 \n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "batches = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "\n",
    "batch_error = []\n",
    "for sd in range(1,6):\n",
    "    seed(sd)\n",
    "    set_seed(sd)\n",
    "    x_trains, x_val, y_trains, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=sd)\n",
    "    \n",
    "    print(\"Seed\", sd, end=': ')\n",
    "    for batch_size in batches:\n",
    "        print(batch_size, end=' ')\n",
    "        seed(sd)\n",
    "        set_seed(sd)\n",
    "        \n",
    "        model = my_dnn((x_trains.shape[1],))\n",
    "        model.compile(optimizer=keras.optimizers.Adam(0.02), loss='mse')\n",
    "\n",
    "        history = model.fit(x_trains, y_trains, epochs=epochs, batch_size=batch_size,\n",
    "                             callbacks=[callbacklr], verbose=0)\n",
    "\n",
    "        score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "        batch_error.append(score)\n",
    "        \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size = 2, Erros de Validação MSE = 15.9616\n",
      "Batch size = 4, Erros de Validação MSE = 14.7216\n",
      "Batch size = 8, Erros de Validação MSE = 13.0232\n",
      "Batch size = 16, Erros de Validação MSE = 13.5529\n",
      "Batch size = 32, Erros de Validação MSE = 15.1462\n",
      "Batch size = 64, Erros de Validação MSE = 21.8933\n",
      "Batch size = 128, Erros de Validação MSE = 33.4003\n",
      "Batch size = 256, Erros de Validação MSE = 67.6051\n"
     ]
    }
   ],
   "source": [
    "batch_error = np.array(batch_error)        \n",
    "batch_error = batch_error.reshape((5,len(batches)))\n",
    "\n",
    "mean_error_batches = np.mean(batch_error, axis=0)\n",
    "for bs, me in zip(batches, mean_error_batches):\n",
    "       print(\"Batch size = %d, Erros de Validação MSE = %.4f\" % (bs, me))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3zlC0i0yqrX"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 8)\n",
    "\n",
    "O que podemos concluir dos dois exercícios anteriores (7 e 8)?\n",
    "\n",
    "(a) Os valores padrão para os hiperparâmetros geram bons resultados. A busca por outros parâmetros pode não valer a pena pois a diferença alcançada observada é pequena.<br>\n",
    "(b) Devemos sempre utilizar Adam com decaimento de taxa de aprendizado e batch size de tamanho entre 8 e 64, sendo que o uso do padrão (32) é normalmente suficiente.<br>\n",
    "(c) Batchs de tamanho muito grande são prejudiciais ao treinamento, e o otimizador Adam é sempre melhor com decaimento de taxa de aprendizado.<br>\n",
    "<font color='red'>(d) O uso de hiperparâmetros com valores padrão pode gerar resultados subótimos, sendo importante uma busca de parâmetros para melhor otimizar modelos</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batchs de tamanho muito grande têm a tendência de serem prejudiciais ao treinamento.<br>\n",
    "\n",
    "Os otimizadores (SGD ou Adam) devem ser estudados em conjunto com o decaimento da taxa de aprendizado.<br>\n",
    "O SGD normalmente melhora com o uso do Momentum (que aumenta o valor do lr em regiões de maior gradiente e vice-versa).<br<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parte 2 - Exercícios Complementares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    " ### Exercício 9)\n",
    "\n",
    "Considere 4 funções de custo distintas: 1. entropia cruzada binária, 2. perda quadrática, vistas em aula, e mais duas adicionais:\n",
    "\n",
    "3. Perda 0-1\n",
    "\n",
    "$$\\frac{1}{N} \\sum_{i=1}^N \n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t0  & \\mbox{if } y_i = \\hat{y}_i \\\\\n",
    "\t\t1 & \\mbox{if } y_i \\neq \\hat{y}_i \n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "4. Perda SVM/Hinge\n",
    " \n",
    "$$\\frac{1}{N} \\sum_{i=1}^N \\max(0, 1- y^{h}_i\\cdot f(x_i)),$$\n",
    "essa função considera que as classes são -1 e 1, sendo $f(x_i)=\\hat{y}_i^{h}$ um valor de saída considerando valores negativos (os quais gerarão classificação para a classe -1) e positivos (classificação para a classe 1). Portanto será preciso adaptar as classes do problema e a  saída $\\hat{y}^{h}$ para esse cenário da seguinte forma:\n",
    "* $y^{h} \\in \\{-1,1\\}$, e\n",
    "* $\\hat{y}^{h} = 2\\cdot(\\hat{y}-0.5)$,\n",
    "sendo $\\hat{y}$ a probabilidade de uma instância pertencer à classe positiva (1).\n",
    "\n",
    "Considere o exemplo dado em aula, com os pontos unidimensionais conforme o código abaixo.\n",
    "\n",
    "A seguir, treine um classificador de Regressão Logística com solver `lbfgs` e compute as quatro perdas nesse conjunto de dados após o treinamento. Note que as perdas 1,2 e 4 são calculadas com base nas probabilidades, enquanto que 3 é calculada com base na classificação.\n",
    "\n",
    "Imprima as perdas por instância para inspeção e logo após a perda média no conjunto de treinamento. Qual a ordem de magnitude das perdas, da menor para a maior?\n",
    "\n",
    "(a) Hinge, Quadrática, Entropia Cruzada, 0-1<br>\n",
    "(b) Quadrática, Entropia Cruzada, Hinge e 0-1<br>\n",
    "(c) 0-1, Quadrática, Entropia Cruzada, Hinge<br>\n",
    "<font color='red'>(d) Quadrática, 0-1, Entropia Cruzada, Hinge</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "6uamxcISyqpv",
    "outputId": "0bcb9cab-624c-41d0-fe3f-a908efb7c1a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1497ea54dc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([-1.8,-1.5,-0.8,-0.4,-0.2, 0.0, 0.1, 0.5, 1.0, 1.3])\n",
    "y = np.array([ 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,  1.0, 1.0, 1.0])\n",
    "yh = np.array([ -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "plt.scatter(x,np.zeros(10), c=y,cmap=plt.cm.coolwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y     = [0. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "y_hat = [0.133 0.178 0.325 0.433 0.49  0.547 0.576 0.682 0.792 0.843]\n"
     ]
    }
   ],
   "source": [
    "# Treinando um classificador para diferenciar 2 classes (0 e 1)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression(solver='lbfgs')\n",
    "logr.fit(x.reshape(-1, 1), y)\n",
    "\n",
    "# vamos pegar as probabilidades de cada elemento pertencer a classe 1\n",
    "y_hat = logr.predict_proba(x.reshape(-1, 1))[:, 1].ravel()\n",
    "\n",
    "# pegando as probabilidades de saída\n",
    "print('y     = {}'.format(np.round(y , 3)))\n",
    "print('y_hat = {}'.format(np.round(y_hat, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat_hi= [-0.735 -0.645 -0.349 -0.134 -0.02   0.095  0.151  0.365  0.585  0.687]\n",
      "1-y*y_hat= [0.265 0.355 0.651 1.134 0.98  0.905 1.151 0.635 0.415 0.313]\n"
     ]
    }
   ],
   "source": [
    "# classificando para calcular a perda 0-1\n",
    "y_clas = y_hat.copy()\n",
    "y_clas[y_clas>=0.5] = 1\n",
    "y_clas[y_clas<0.5] = 0\n",
    "\n",
    "# calculando a saída hinge, entre -1 e 1\n",
    "y_hat_hi = (y_hat-0.5)*2\n",
    "print('y_hat_hi= {}'.format(np.round(y_hat_hi, 3)))\n",
    "\n",
    "# perda quadrática\n",
    "loss_qu = np.power(y-y_hat,2)\n",
    "# perda de entropia cruzada\n",
    "loss_ec = -(y*np.log(y_hat+.00001) + (1-y)*np.log(1-y_hat +.00001))\n",
    "# perda zero-um\n",
    "loss_01 = (y!=y_clas)*1\n",
    "\n",
    "# perda hinge\n",
    "hi_mult = 1-(yh*y_hat_hi)\n",
    "loss_hi = [max(0,mi) for mi in hi_mult]\n",
    "print('1-y*y_hat= {}'.format(np.round(hi_mult, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdas calculadas por instância:\n",
      "[0.018 0.032 0.106 0.321 0.24  0.205 0.331 0.101 0.043 0.025]\n",
      "[0.142 0.195 0.394 0.837 0.674 0.603 0.857 0.382 0.233 0.17 ]\n",
      "[0 0 0 1 0 0 1 0 0 0]\n",
      "[0.265 0.355 0.651 1.134 0.98  0.905 1.151 0.635 0.415 0.313]\n",
      "\n",
      "Perda quadrática = 0.1421\n",
      "Entropia cruzada = 0.4487\n",
      "Perda 0-1        = 0.2000\n",
      "Perda hinge/svm  = 0.6805\n"
     ]
    }
   ],
   "source": [
    "print(\"Perdas calculadas por instância:\")\n",
    "print(np.round(loss_qu,3))\n",
    "print(np.round(loss_ec,3))\n",
    "print(np.round(loss_01,3))\n",
    "print(np.round(loss_hi,3))\n",
    "print()\n",
    "\n",
    "print(\"Perda quadrática = %.4f\" % (np.mean(loss_qu)))\n",
    "print(\"Entropia cruzada = %.4f\" % (np.mean(loss_ec)))\n",
    "print(\"Perda 0-1        = %.4f\" % (np.mean(loss_01)))\n",
    "print(\"Perda hinge/svm  = %.4f\" % (np.mean(loss_hi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OLlz13JyqrX"
   },
   "source": [
    "---\n",
    "\n",
    "### Exercício 10)\n",
    "\n",
    "Carregue a base de dados Fashion MNIST\n",
    "\n",
    "Crie duas redes neurais utilizando os blocos Residuais e módulos Inception conforme visto em aula.\n",
    "\n",
    "* InceptionNet\n",
    "    * Módulo Inception V1 com número de filtros: 32, 32, 32, 32, 32, 16\n",
    "    * Maxpooling com pool=2, stride=2\n",
    "    * Módulo Inception V1 com número de filtros: 32, 64, 64, 64, 64, 16\n",
    "    * Maxpooling com pool=2, stride=2\n",
    "* ResNet\n",
    "    * 3 blocos residuais com 64 filtros, cada um seguido por camada Maxpooling com pool=2, stride=2\n",
    "\n",
    "Ambos devem possuir uma camada `GlobalAveragePooling2D` antes da camada de predição.\n",
    "\n",
    "Treine ambas com SGD, learning rate 0.02 e momentum 0.8, utilizando batchsize 32, e apenas as 1000 primeiras imagens do dataset de treinamento (use :1000), por 80 épocas. Antes de compilar e treinar cada modelo, defina as sementes numpy e tensorflow de forma fixa para 1.\n",
    "\n",
    "Exiba o gráfico da perda ao longo das épocas para as duas arquiteturas, e ao final compute e mostre a perda e a acurácia no treinamento (1000 imagens) e num conjunto de validação formado pelas próximas 1000 imagens de treinamento (use 1000:2000). \n",
    "\n",
    "Marque a alternativa que melhor se encaixa no resultado observado e sua conclusão.\n",
    "\n",
    "(a) Ambas convergem rapidamente para esse subconjunto e se ajustam aos dados de treinamento, mas falham em generalizar para o conjunto de validação<br>\n",
    "(b) A Inception converge mais rapidamente quando comparda à ResNet e se ajusta perfeitamente aos dados de treinamento, mas com perda mais alta calculada na validação, indicando overfitting, enquanto a ResNet generaliza melhor e poderia ser treinada por mais épocas<br>\n",
    "<font color='red'>(c) A ResNet converge mais rapidamente quando comparada à Inception e se ajusta perfeitamente aos dados de treinamento, mas com perda mais alta calculada na validação, indicando overfitting, enquanto a Inception generaliza melhor e poderia ser treinada por mais épocas</font><br>\n",
    "(d) A ResNet converge mais rapidamente quando comparada à Inception e se ajusta perfeitamente aos dados de treinamento. Ambas possuem generalização similar o conjunto de validação.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "RVYNMoriyqrZ",
    "outputId": "b866fc9c-2d4e-425b-e849-29222f900bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "26435584/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n",
      "(60000, 28, 28)\n",
      "Shape:  (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# carregando datasets do keras\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# obtendo informações das imagens (resolucao) e dos rótulos (número de classes)\n",
    "img_lin, img_col = x_train.shape[1], x_train.shape[2]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "# dividir por 255 para obter normalizacao\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# transformar categorias em one-hot-encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# verifica imagens da base de dados tem 3 canais (RGB) ou apenas 1 (escala de cinza)\n",
    "if (len(x_train.shape) == 3):\n",
    "      n_channels = 1\n",
    "else:\n",
    "      n_channels = x_train.shape[3]\n",
    "\n",
    "# re-formata o array de forma a encontrar o formato da entrada (input_shape)\n",
    "# se a dimensão dos canais vem primeiro ou após a imagem\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], n_channels, img_lin, img_col)\n",
    "    x_test = x_test.reshape(x_test.shape[0], n_channels, img_lin, img_col)\n",
    "    input_shape = (n_channels, img_lin, img_col)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_lin, img_col, n_channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_lin, img_col, n_channels)\n",
    "    input_shape = (img_lin, img_col, n_channels)\n",
    "\n",
    "print(\"Shape: \", input_shape)\n",
    "print(\"Número de Classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Módulo Inception V1 com número de filtros: 32, 32, 32, 32, 32, 16<br>\n",
    "Maxpooling com pool=2, stride=2<br>\n",
    "Módulo Inception V1 com número de filtros: 32, 64, 64, 64, 64, 16<br>\n",
    "Maxpooling com pool=2, stride=2<br>\n",
    "GlobalAveragePooling2D antes da camada de predição<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 32)   64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 32)   9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 32)   25632       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 16)   32          max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 112)  0           conv2d[0][0]                     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 112)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 64)   7232        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 64)   7232        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 112)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 32)   3616        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 64)   102464      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 14, 14, 16)   1808        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 176)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 176)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 176)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 10)           1770        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 196,154\n",
      "Trainable params: 196,154\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def inception_module(layer_in, f1_out, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
    "    # 1x1 conv\n",
    "    conv1 = Conv2D(f1_out, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    # 3x3 conv\n",
    "    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
    "    # 5x5 conv\n",
    "    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
    "    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
    "    # 3x3 max pooling\n",
    "    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
    "    layer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return layer_out\n",
    " \n",
    "# definir entrada\n",
    "input_layer = Input(shape=input_shape)\n",
    "# adicionar módulos inception\n",
    "layer1 = inception_module(input_layer, 32, 32, 32, 32, 32, 16)\n",
    "pool1 = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer1) #\n",
    "layer2 = inception_module(pool1, 32, 64, 64, 64, 64, 16) # rem?\n",
    "pool2 = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer2)\n",
    "flatt = keras.layers.GlobalAveragePooling2D()(pool2)\n",
    "\n",
    "softmax = keras.layers.Dense(num_classes, activation='softmax')(flatt)\n",
    "\n",
    "# cria modelo definindo camada de entrada e camada de saída\n",
    "Inception = keras.models.Model(inputs=input_layer, outputs=softmax)\n",
    "Inception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 blocos residuais com 64 filtros, cada um seguido por camada Maxpooling com pool=2, stride=2<br>\n",
    "1 camada GlobalAveragePooling2D antes da camada de predição.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 64)   640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 64)   36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 64)   128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 28, 28, 64)   0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 14, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 14, 64)   36928       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 64)   0           conv2d_16[0][0]                  \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 64)     36928       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 64)     36928       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 64)     0           conv2d_18[0][0]                  \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7, 7, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_163 (Dense)               (None, 10)           650         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 186,058\n",
      "Trainable params: 186,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import add\n",
    "\n",
    "# funcao que retorna um bloco residual\n",
    "# merge_input é criada para possibilitar a concatenação caso as dimensões sejam diferentes\n",
    "# kernel_initializer 'he_normal' é para tipificar a rede como residual\n",
    "# activation 'linear' é importante para poder fazer a soma depois\n",
    "# função de ativação de saída pode ser 'relu' porque a camada 'add' não tem função de ativação\n",
    "\n",
    "def residual_block(layer_in, n_filters):\n",
    "    merge_input = layer_in\n",
    "    #verifica se é necessária uma primeira camada para deixar o número de filtros iguais para adição\n",
    "    if layer_in.shape[-1] != n_filters:\n",
    "        merge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "    # conv1\n",
    "    conv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n",
    "    # conv2\n",
    "    conv2 = Conv2D(n_filters, (3,3), padding='same', activation='linear', kernel_initializer='he_normal')(conv1)\n",
    "    # soma entrada com saída (pulou 2 camadas)\n",
    "    layer_out = add([conv2, merge_input])\n",
    "    # função de ativação da saída do bloco\n",
    "    layer_out = keras.layers.Activation('relu')(layer_out)\n",
    "    return layer_out\n",
    " \n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "layer1 = residual_block(input_layer, 64)\n",
    "pool1 = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer1)\n",
    "layer2 = residual_block(pool1, 64)\n",
    "pool2 = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer2)\n",
    "layer3 = residual_block(pool2, 64)\n",
    "pool3 = MaxPooling2D((2,2), strides=(2,2), padding='same')(layer3)\n",
    "flatt = keras.layers.GlobalAveragePooling2D()(pool3)\n",
    "softmax = keras.layers.Dense(num_classes, activation='softmax')(flatt)\n",
    "\n",
    "ResNet = keras.models.Model(inputs=input_layer, outputs=softmax)\n",
    "ResNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treine ambas com SGD, learning rate 0.02 e momentum 0.8, utilizando batchsize 32, e apenas as 1000 primeiras imagens do dataset de treinamento (use :1000), por 80 épocas. Antes de compilar e treinar cada modelo, defina as sementes numpy e tensorflow de forma fixa para 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = x_train[:1000]\n",
    "y_sub = y_train[:1000]\n",
    "\n",
    "x_val = x_train[1000:2000]\n",
    "y_val = y_train[1000:2000]\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as sementes ajudam a ter resultados reproduzíveis\n",
    "#tf.keras.backend.clear_session()\n",
    "seed(1)\n",
    "set_seed(1)\n",
    "\n",
    "Inception.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.02, momentum=0.8),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histInc = Inception.fit(x_sub, y_sub,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as sementes ajudam a ter resultados reproduzíveis\n",
    "#tf.keras.backend.clear_session()\n",
    "seed(1)\n",
    "set_seed(1)\n",
    "\n",
    "ResNet.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.02, momentum=0.8),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histResNet = ResNet.fit(x_sub, y_sub,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exiba o gráfico da perda ao longo das épocas para as duas arquiteturas, e ao final compute e mostre a perda e a acurácia no treinamento (1000 imagens) e num conjunto de validação formado pelas próximas 1000 imagens de treinamento (use 1000:2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14987cde820>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(histInc.history['loss'])\n",
    "plt.plot(histResNet.history['loss'])\n",
    "plt.legend([\"Inception\", \"ResNet\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_inception_train = Inception.evaluate(x_sub, y_sub, verbose = 0)\n",
    "score_resnet_train = ResNet.evaluate(x_sub, y_sub, verbose = 0)\n",
    "\n",
    "score_inception_val = Inception.evaluate(x_val, y_val, verbose = 0)\n",
    "score_resnet_val = ResNet.evaluate(x_val, y_val, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Treinamento = Loss 0.001, Accuracy 1.000\n",
      "Inception Validação   = Loss 0.658, Accuracy 0.875\n",
      "ResNet Treinamento    = Loss 0.000, Accuracy 1.000\n",
      "ResNet Validação      = Loss 1.411, Accuracy 0.830\n"
     ]
    }
   ],
   "source": [
    "print(\"Inception Treinamento = Loss %.3f, Accuracy %.3f\" % (score_inception_train[0], score_inception_train[1]))\n",
    "print(\"Inception Validação   = Loss %.3f, Accuracy %.3f\" % (score_inception_val[0], score_inception_val[1]))\n",
    "\n",
    "print(\"ResNet Treinamento    = Loss %.3f, Accuracy %.3f\" % (score_resnet_train[0], score_resnet_train[1]))\n",
    "print(\"ResNet Validação      = Loss %.3f, Accuracy %.3f\" % (score_resnet_val[0], score_resnet_val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-03-Exercicios_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
