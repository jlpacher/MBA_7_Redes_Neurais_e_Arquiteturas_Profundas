{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvaEK6Bn-wwG"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo 6 - Redes neurais para dados sequenciais</span>\n",
    "\n",
    "#### <span style=\"color:darkred\">**Parte 2: Word Embedding**</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wvtQgvYq_z7v"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hVCHWi9KriW"
   },
   "source": [
    "## Carregando representações pré-treinadas em português \n",
    "\n",
    "Após salvar, vamos montar um dicionário com palavra/vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "2E5iOeI4lqbm",
    "outputId": "da8d9c0d-5364-42cd-b816-9d5bd6e54d19"
   },
   "outputs": [],
   "source": [
    "#!wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "-xsQ97N_pmUn",
    "outputId": "f0380e31-9988-4757-d2cf-a343cc053414"
   },
   "outputs": [],
   "source": [
    "#!mv download.php?file=embeddings%2Fglove%2Fglove_s50.zip glove_s50.zip\n",
    "#!unzip -q glove_s50.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s50 : 50 dimensões por palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "KgO7dF4s9D7X",
    "outputId": "0f79d0be-3544-4fcd-b1e0-2fdf474d54da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-70b59e83ceaf>:18: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  coefs = np.fromstring(coefs, \"f\", sep=\" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 929594 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# path_to_glove_file = os.path.join(\n",
    "#     os.path.expanduser(\"~\"), \"/content/glove_s50.txt\" # colab\n",
    "# )\n",
    "\n",
    "path_to_glove_file = \"./glove_s50.txt\"  # jupyter\n",
    "# path_to_glove_file = \"glove_s50.txt\"  # jupyter\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf-8\", mode='r') as f: \n",
    "# with open(path_to_glove_file, encoding=\"utf-8\", errors = 'backslashreplace') as f:\n",
    "# with open(path_to_glove_file, encoding=\"utf-8\") as f:\n",
    "# with open(path_to_glove_file, encoding=\"latin1\") as f:    \n",
    "# with open(path_to_glove_file, encoding=\"cp1252\") as f:\n",
    "# with open(path_to_glove_file, encoding=\"ISO-8859-1\") as f:\n",
    "# with open(path_to_glove_file) as f:   \n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Encontrados %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path_to_glove_file = \"./glove_s50.txt\"  # jupyter\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding='utf-8', mode='r') as f:\n",
    "    #leitura do cabecalho\n",
    "    header = next(f).strip().split(' ')\n",
    "    tot = int(header[0])\n",
    "    dim = int(header[1])\n",
    "    print('Arquivo: total de linhas %d, dimensoes %d' % (tot,dim))\n",
    "    il = 0\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        try:\n",
    "            coefs = np.array([float(s) for s in coefs.split(' ')])\n",
    "            embeddings_index[word] = coefs\n",
    "            il += 1\n",
    "        except:\n",
    "            print('Problema ao processar', end=' ')\n",
    "            print(il, word)\n",
    "        \n",
    "# remover chave com problema\n",
    "if word in embeddings_index: embeddings_index.pop(word)\n",
    "\n",
    "print(\"Encontrados %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "EBPgAvQHrk-f",
    "outputId": "de4cd802-4270-44e8-aa5a-c322c3b6c14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.984870e-01  1.938170e-01  1.839920e-01 -2.590166e+00 -3.155430e-01\n",
      " -1.469410e-01  1.290320e-01  3.814410e-01 -4.846610e-01  3.721310e-01\n",
      "  6.471990e-01 -1.248160e+00 -3.151210e-01  3.676890e-01 -7.965720e-01\n",
      "  2.589710e-01 -1.260200e-02 -6.782460e-01 -4.735670e-01  3.739230e-01\n",
      "  1.437597e+00  2.001800e-02  9.999200e-02 -1.829620e-01  2.779400e-01\n",
      "  1.222500e-01 -2.345070e-01 -7.791430e-01  6.422940e-01  3.167230e-01\n",
      " -3.914640e-01  3.333300e-01  2.291640e-01 -9.465310e-01 -2.157560e-01\n",
      " -3.246800e-02 -3.029230e-01  9.146800e-02 -1.788646e+00 -2.995630e-01\n",
      " -3.183580e-01 -7.586490e-01  2.524000e-03 -6.656960e-01  7.843900e-01\n",
      "  1.341660e-01  6.273990e-01  3.014050e-01 -4.354190e-01  1.121057e+00]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# vetores da palavra aprovação\n",
    "print(embeddings_index['aprovação'])\n",
    "print(len(embeddings_index['aprovação']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy0O2L2WK6D7"
   },
   "source": [
    "## Base de dados: rumor Brazil 2018\n",
    "\n",
    "Base de dados de texto para classificação em frases \"falsas\" ou \"verdadeiras\" conforme checado por agências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "RNykW-NnniWS",
    "outputId": "9b3863ff-dda5-4dcb-c471-e52229b6c8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Salário Mínimo: R$ 950,00. Bolsa Presidiário: ...\n",
      "1    Empresa contratada pelo TSE para apuração dos ...\n",
      "2    O Aloizio Mercadante, ministro da Educação, mo...\n",
      "3    Há um complô espalhando fake news descaradas e...\n",
      "4    Somente em 2017, mais de 800 milhões de tonela...\n",
      "5    Nunca vi o Lula pronunciar essa palavra fascis...\n",
      "6    O Mourão, por exemplo, foi ele próprio tortura...\n",
      "7    O PSB, todos os seus governadores e o seu pres...\n",
      "8    Bolsonaro Nunca aprovou um projeto de seguranç...\n",
      "9    Ele Lula não pode aparecer mais que 25% no hor...\n",
      "Name: texto, dtype: object\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    1\n",
      "9    1\n",
      "Name: rotulo, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/rumor-election-brazil-2018.csv\", delimiter=';')\n",
    "texto = df['texto']\n",
    "rotulos = (df['rotulo']=='VERDADE').astype(int)\n",
    "\n",
    "class_names = [\"FALSO\", \"VERDADEIRO\"]\n",
    "\n",
    "print(texto[:10])\n",
    "print(rotulos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239 221]\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(rotulos)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "EQ11lJuvFr-i",
    "outputId": "441617a0-6310-4538-90a2-4d18b7dba71b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-87b77ae273f0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rng.shuffle(texto)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "rng.shuffle(texto)\n",
    "rng = np.random.RandomState(1)\n",
    "rng.shuffle(rotulos)\n",
    "\n",
    "validation_split = 0.1\n",
    "num_validation = int(validation_split * len(texto))\n",
    "x_train = texto[:-num_validation]\n",
    "x_val = texto[-num_validation:]\n",
    "y_train = rotulos[:-num_validation]\n",
    "y_val = rotulos[-num_validation:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2-a0lZutC7b"
   },
   "source": [
    "Vocabulário irá considerar até 20 mil palavras, e irá truncar sequências com mais de 32 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokens = palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T-L2MpeWsNx5"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-192207f074fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mvoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mword_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\u001b[0m in \u001b[0;36mget_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0mvocabulary\u001b[0m \u001b[0mwill\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude\u001b[0m \u001b[0many\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mOOV\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \"\"\"\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_special_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\index_lookup.py\u001b[0m in \u001b[0;36mget_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    300\u001b[0m       \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m       \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_vocab_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     lookup = collections.defaultdict(lambda: self.oov_token,\n\u001b[0;32m    304\u001b[0m                                      zip(indices, vocab))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py\u001b[0m in \u001b[0;36m_tensor_vocab_to_numpy\u001b[1;34m(self, vocabulary)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_tensor_vocab_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_tensor_vocab_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_text\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=32)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(x_train).batch(16)\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-EOJZN3LGFx"
   },
   "source": [
    "Podemos ver o resultado do vetorizador, que exibe 1 para palavras fora do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "h0_DF96isQQI",
    "outputId": "ac69934b-7f35-4758-ab27-32ac58bce0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 92,  1,  1,  1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"um dois one two three\"]])\n",
    "output.numpy()[0, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIRN7jpDLLnW"
   },
   "source": [
    "Abaixo, considerando o número de tokens (palavras) da base de dados, vamos tentar gerar seus embedding vectors.\n",
    "\n",
    "Palavras fora do vocabulário não são convertidas. Comumente artigos, números e outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "QgD5_4jLsCz9",
    "outputId": "c06b75af-bfbc-442e-e4de-0f06ec952c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens:  1944\n",
      "(1944, 50)\n",
      "Palavras convertidas: 1785 / não convertidas: 157)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "print(\"Número de tokens: \", num_tokens)\n",
    "embedding_dim = 50\n",
    "convertidas = 0\n",
    "falhas = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        if (embedding_vector.shape[0] != embedding_dim):\n",
    "          falhas += 1\n",
    "        else:\n",
    "          # Words not found in embedding index will be all-zeros.\n",
    "          # This includes the representation for \"padding\" and \"OOV\"\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "          convertidas += 1\n",
    "    else:\n",
    "        falhas += 1\n",
    "\n",
    "print(\"Palavras convertidas: %d / não convertidas: %d)\" % (convertidas, falhas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i7ACPhgLhEX"
   },
   "source": [
    "Montando a base de dados para o treinamento, no formato numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada sentença tem no máximo 32 tokens (limite fixado no código acima): output_sequence_length=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "aJ3zdvrs8hCJ",
    "outputId": "042181f3-9eca-4926-ec5a-15fd1766f517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 32)\n",
      "(46, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in x_train])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in x_val])).numpy()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB8_ADE9LkHC"
   },
   "source": [
    "## Camada de \"Word Embedding\"\n",
    "\n",
    "Para isso devemos informar o número de palavras, a dimensionalidade e passar a matrix com pesos pré-treinados.\n",
    "\n",
    "Caso não utilizemos os parâmetros `embeddings_initializer`, os pesos serão aleatórios.\n",
    "\n",
    "Também deixamos essa camada não treinável pois não queremos modificar as representações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WKNJE4NpHdu0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decaimento de learning rate\n",
    "def scheduler(epoch, lr):\n",
    "    if (epoch % 5 == 0): print(\"Época %04d - learning rate %.9f\" % (epoch, lr))\n",
    "    if (epoch+1 < 5):\n",
    "        return lr\n",
    "    else:\n",
    "        return np.round(lr * tf.math.exp(-0.005),9)\n",
    "\n",
    "callbacklr = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3ClTHexL5j5"
   },
   "source": [
    "### Modelo baseado em Convoluções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "Vx6B7fRkr-yY",
    "outputId": "9e81f640-2993-4392-d1f7-6d20e5dbe60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 50)          97200     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 64)          6464      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 128)         24704     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 136,689\n",
      "Trainable params: 39,489\n",
      "Non-trainable params: 97,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(64, 2, activation=\"relu\", padding=\"same\")(embedded_sequences)\n",
    "x = layers.Conv1D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "modelConv = keras.Model(int_sequences_input, preds)\n",
    "modelConv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "id": "lYbD6f0eukTT",
    "outputId": "2e6a8df3-feaa-49dd-808d-67c7f55ccbfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Época 0000 - learning rate 0.001000000\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.7456 - acc: 0.4662 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6763 - acc: 0.5845 - val_loss: 0.6802 - val_acc: 0.5435\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6327 - acc: 0.6812 - val_loss: 0.6669 - val_acc: 0.6739\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5970 - acc: 0.7029 - val_loss: 0.6576 - val_acc: 0.6522\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5438 - acc: 0.7609 - val_loss: 0.6579 - val_acc: 0.6522\n",
      "Epoch 6/25\n",
      "Época 0005 - learning rate 0.000995013\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4692 - acc: 0.7657 - val_loss: 0.6720 - val_acc: 0.5870\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4378 - acc: 0.8213 - val_loss: 0.6631 - val_acc: 0.6522\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2793 - acc: 0.9179 - val_loss: 0.6332 - val_acc: 0.7391\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2181 - acc: 0.9517 - val_loss: 0.6983 - val_acc: 0.6739\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1683 - acc: 0.9662 - val_loss: 0.6540 - val_acc: 0.6087\n",
      "Epoch 11/25\n",
      "Época 0010 - learning rate 0.000970446\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0998 - acc: 0.9879 - val_loss: 0.7021 - val_acc: 0.6739\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1052 - acc: 0.9686 - val_loss: 0.7619 - val_acc: 0.6522\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0686 - acc: 0.9879 - val_loss: 0.7631 - val_acc: 0.6739\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0412 - acc: 0.9976 - val_loss: 0.7850 - val_acc: 0.5435\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0300 - acc: 0.9976 - val_loss: 0.8101 - val_acc: 0.6739\n",
      "Epoch 16/25\n",
      "Época 0015 - learning rate 0.000946486\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0256 - acc: 0.9976 - val_loss: 0.8245 - val_acc: 0.6087\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8862 - val_acc: 0.5870\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.8953 - val_acc: 0.6087\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9151 - val_acc: 0.6087\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.0635 - val_acc: 0.5870\n",
      "Epoch 21/25\n",
      "Época 0020 - learning rate 0.000923117\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.9849 - val_acc: 0.6087\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.9853 - val_acc: 0.6304\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.9708 - val_acc: 0.6087\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.9998 - val_acc: 0.5870\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.0031 - val_acc: 0.6087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7a20703c40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelConv.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"acc\"]\n",
    ")\n",
    "modelConv.fit(x_train, y_train, batch_size=16, epochs=25, \n",
    "                  callbacks=[callbacklr], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzIdAcnKMDiz"
   },
   "source": [
    "Podemos agora testar frases novas!\n",
    "\n",
    "Para isso vou criar uma camada de entrada que passa por um vetorizador, e depois alimenta o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "iimkRQpgO5eS",
    "outputId": "cd231c40-b0fd-4355-bcd1-94efaa1e6470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
      "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  VERDADEIRO\n",
      "Acabou a corrupção no Brasil :  VERDADEIRO\n",
      "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
     ]
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "preds = modelConv(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "frase = \"Na pós graduação, as mulheres são maioria\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Acabou a corrupção no Brasil\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
    "classe = (end_to_end_model.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utj_ygXrMLh2"
   },
   "source": [
    "### Modelo utilizando GRU\n",
    "\n",
    "Vamos substituir uma camada convolucional por uma GRU (poderia ser uma LSTM também)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "cLvDalHe6Ol7",
    "outputId": "82c09324-032d-4864-9ddc-af5d0b381cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 50)          97200     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 64)          6464      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                24960     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 132,849\n",
      "Trainable params: 35,649\n",
      "Non-trainable params: 97,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(64, 2, activation=\"relu\", padding=\"same\")(embedded_sequences)\n",
    "x = layers.GRU(64)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predsGRUout = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "modelGRU = keras.Model(inputs=int_sequences_input, outputs=predsGRUout)\n",
    "modelGRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 961
    },
    "id": "BpqJfZgX6poK",
    "outputId": "0db1fa4b-26e9-4524-e67a-e6618141c98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Época 0000 - learning rate 0.001000000\n",
      "26/26 [==============================] - 2s 15ms/step - loss: 0.6929 - acc: 0.4952 - val_loss: 0.7073 - val_acc: 0.5435\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6861 - acc: 0.4952 - val_loss: 0.6992 - val_acc: 0.4348\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6832 - acc: 0.5217 - val_loss: 0.7058 - val_acc: 0.5435\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6735 - acc: 0.5217 - val_loss: 0.7049 - val_acc: 0.4348\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6712 - acc: 0.5242 - val_loss: 0.7069 - val_acc: 0.4783\n",
      "Epoch 6/25\n",
      "Época 0005 - learning rate 0.000995013\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6658 - acc: 0.5386 - val_loss: 0.7039 - val_acc: 0.4565\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6543 - acc: 0.5556 - val_loss: 0.7103 - val_acc: 0.3913\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6474 - acc: 0.5435 - val_loss: 0.6933 - val_acc: 0.5435\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6336 - acc: 0.5966 - val_loss: 0.7432 - val_acc: 0.3696\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6296 - acc: 0.6256 - val_loss: 0.7570 - val_acc: 0.5435\n",
      "Epoch 11/25\n",
      "Época 0010 - learning rate 0.000970446\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6222 - acc: 0.5821 - val_loss: 0.6871 - val_acc: 0.4783\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5964 - acc: 0.6329 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5783 - acc: 0.6836 - val_loss: 0.6800 - val_acc: 0.4783\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5542 - acc: 0.7029 - val_loss: 0.6167 - val_acc: 0.6739\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5554 - acc: 0.7126 - val_loss: 0.6356 - val_acc: 0.6087\n",
      "Epoch 16/25\n",
      "Época 0015 - learning rate 0.000946486\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5894 - acc: 0.7005 - val_loss: 0.6473 - val_acc: 0.6304\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5097 - acc: 0.7729 - val_loss: 0.7038 - val_acc: 0.6304\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5518 - acc: 0.7077 - val_loss: 0.6048 - val_acc: 0.6739\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4976 - acc: 0.7657 - val_loss: 0.6138 - val_acc: 0.5652\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4643 - acc: 0.7536 - val_loss: 0.9709 - val_acc: 0.5870\n",
      "Epoch 21/25\n",
      "Época 0020 - learning rate 0.000923117\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4014 - acc: 0.8213 - val_loss: 0.5628 - val_acc: 0.7826\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3446 - acc: 0.8599 - val_loss: 0.6693 - val_acc: 0.6957\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2944 - acc: 0.8816 - val_loss: 0.6348 - val_acc: 0.7174\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2648 - acc: 0.8889 - val_loss: 0.5510 - val_acc: 0.7391\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2074 - acc: 0.9300 - val_loss: 0.8632 - val_acc: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7a7c304130>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelGRU.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"acc\"]\n",
    ")\n",
    "modelGRU.fit(x_train, y_train, batch_size=16, epochs=25, \n",
    "                  callbacks=[callbacklr], validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "qiLfD7Ln643M",
    "outputId": "f84c2e2e-f6ae-4a43-d60c-b90d87f95aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na pós graduação, as mulheres são maioria :  VERDADEIRO\n",
      "As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido :  FALSO\n",
      "Acabou a corrupção no Brasil :  FALSO\n",
      "Para poder ganhar eleições, presidente faz aliança com partidos grandes :  VERDADEIRO\n"
     ]
    }
   ],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "predsGRU = modelGRU(x)\n",
    "end_to_end_modelGRU = keras.Model(string_input, predsGRU)\n",
    "\n",
    "frase = \"Na pós graduação, as mulheres são maioria\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"As queimadas esse ano são equivalentes a uma área do tamanho do Reino Unido\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Acabou a corrupção no Brasil\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])\n",
    "\n",
    "frase = \"Para poder ganhar eleições, presidente faz aliança com partidos grandes\"\n",
    "classe = (end_to_end_modelGRU.predict([[frase]])[0] > 0.5).astype(int)\n",
    "print(frase, ': ', class_names[classe[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-06-Aula-notebook2_wordembedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
