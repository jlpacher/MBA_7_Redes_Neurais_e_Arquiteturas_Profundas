{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo VIII -  Tópicos em Deep Learning</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "As respostas devem ser dadas no Moodle.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "### Questão 1)\n",
    "\n",
    "Qual das funções de custo abaixo (e suas variações) é mais adequada como base para treinar uma rede neural para um problema em que se tenha como entrada imagens de um circuito produzido e anotações no formato de diversas regiões contendo falhas e defeitos, sendo a saída as coordenadas de regiões da imagem contendo os defeitos/falhas?\n",
    "\n",
    "(a) Entropia Cruzada.<br>\n",
    "<font color='red'>(b) Intersecção sobre união</font><br>\n",
    "(c) Acurácia<br>\n",
    "(d) Função contrastiva<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecção de objetos: classificação+regressão => classifica (regiões com falhas ou defeitos) e a localiza (coordenadas das regiões), gerando uma caixa (\"bounding box\"). <br>\n",
    "Vetor de saída y = [1, bx, by, bh, bw, Classe0, Classe1...] <br>\n",
    "IoU é uma medida de confiança na classificação.<br>\n",
    "IoU = area of overlap / area of union <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 2)\n",
    "\n",
    "Sendo duas arquiteturas: uma do tipo UNet (para predições pixel-a-pixel de imagens de entrada) e outra Autoencoder (esse treinado para aprendizado de representações de imagens). Considere que temos seus modelos já treinados. O interesse principal está na saída de qual componente de cada um desses modelos? \n",
    "\n",
    "<font color='red'> (a) Na UNet temos interesse na saída do decoder, enquanto que no Autoencoder na saída do encoder.</font><br>\n",
    " (b) Na UNet temos interesse na saída do encoder, enquanto que no Autoencoder na saída do decoder<br>\n",
    " (c) Em ambos os casos queremos a saída do encoder<br>\n",
    " (d) Em ambos os casos queremos a saída do decoder<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrada => Encoder => Código (Embedding: espaço latente) => Decoder +> Saída"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 3)\n",
    "\n",
    "Considere um problema de identificar um usuário de um sistema por meio de features relacionadas à interação em uma sessão como: horário de login, sistemas e opções acessadas com horário de acesso, entre outros. Uma instância representa dados de uma sessão de um usuário com o sistema. Considere ainda que nesse cenário temos usuários na ordem de centenas de milhares e que eventualmente é preciso usar um modelo atual para obter representações para usuários futuros não usados no treinamento. Ao utilizar redes neurais profundas para aprender boas representações para usuários que permita identificá-los unicamente de maneira efetiva, qual das funções de custo e estratégia de treinamento é a mais adequada?\n",
    "\n",
    " (a) Classificação com regressão usando como custo o f-score médio dos usuários<br>\n",
    "<font color='red'> (b) Aprendizado constrastivo selecionando pares de usuários</font><br>\n",
    " (c) Análise de agrupamentos usando k-Médias com k igual ao número de usuários para segmentá-los<br>\n",
    " (d) Classificação usando como custo a entropia cruzada<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendizado contrastivo é usado para conectar 2 redes neurais.<br>\n",
    "Normalmente são usadas quando os 2 modelos são iguais (domínios iguais, ex: texto) e chamadas de Redes Siamesas.<br>\n",
    "Quando os modelos são distintos são usadas as Redes Triplet.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Considere um problema que possui uma base de dados alvo com grande quantidade de dados brutos relativos a exemplos não anotados/rotulados e uma parte menor de dados rotulados. A proporção é de 98% de dados não rotulados e 2% de dados rotulados. Quais das técnicas abaixo deve ser utilizada para gerar um modelo de classificação por meio de redes neurais que aproveite os dados disponíveis?\n",
    "\n",
    "(a) Aprendizado contrastivo utilizando função de custo triplet com os dados rotulados e posterior uso da representação aprendida em classificadores externos como o k-NN ou SVM<br>\n",
    "<font color='red'>(b) Aprendizado auto-supervisionado para pré-treinamento com dados não rotulados seguido do treinamento da tarefa de classificação com os dados rotulados</font><br>\n",
    "(c) Clustering (com método de análise de agrupamento) utilizando os dados não rotulados, e classificação dos dados rotulados com base nos clusters obtidos<br>\n",
    "(d) Uso de uma rede neural pré-treinada com outra base de dados (diferente da base alvo), aumento dos dados rotulados da base alvo garantindo balanceamento das classes e treinamento de uma rede neural para classificação com os dados rotulados aumentados<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aprendizado auto-supervisionado é muito usado para tratar problemas com falta de dados rotulados.<br>\n",
    "A proporção de dados rotulados da base é inexpressiva(2%) e, portanto, não há perda em não considerá-los para o treinamento.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "O método BERT para trabalhar com dados textuais com base em tokens por palavra permite adaptar novas tarefas sobre o modelo original. Considere as seguintes afirmacões sobre o método:\n",
    "\n",
    "I - cada palavra distinta produz na saída uma única representação vetorial (embedding) independente da sentença em que apareça<br>\n",
    "II - o modelo original foi treinado com dados não rotulados<br>\n",
    "III - considera as sequências de entrada do inicio para o fim e do fim para o início durante o treinamento<br>\n",
    "IV - gera como saída embeddings para cada token de entrada, além de embeddings adicionais para tokens de controle<br>\n",
    "V - o embedding de saída referente ao token de controle indicando início é comumente usado para classificação<br>\n",
    "\n",
    "Quais das afirmações são corretas sobre o BERT?\n",
    "\n",
    "(a) II, III, IV<br>\n",
    "(b) I, II, V<br>\n",
    "(c) I, III, IV, V<br>\n",
    "<font color='red'>(d) II, III, IV, V </font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I-NOK  O método BERT utiliza a ideia do método ELMo que olha a sentença antes de atribuir o vetor à palavra, mas com Transformers e não com LSTM <br>\n",
    "II-OK   Os datasets para o treinamento do BERT em inglês foram o Book Corpus: 800M palavras + Wikipedia Inglês: 2.4B palavras <br>\n",
    "III-OK  Usa transformers bidirecionais, que olha as sequências de entrada do início para o fim e também do fim para o início <br>\n",
    "IV-OK   Gera embeddings para cada token de entrada e também para os tokens de controle (CLS: início da sentença; SEP: separação entre sentenças/final da sentença <br>\n",
    "V-OK O embedding de saída do token CLS (início) é usado para Classificação, e os da última sentença para encontrar resposta em texto (Start/End Span) <br>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Avaliacao_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
