{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo V - Redes neurais auto-associativas e geradoras</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "As respostas devem ser dadas no Moodle, use esse notebook apenas para gerar o código necessário para obter as respostas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "### Questão 1)\n",
    "\n",
    "Qual a **diferença** entre um Autoencoder convencional (AE) e um Variational Autoencoder (VAE)?\n",
    "\n",
    "(a) VAE aprende uma representação latente com base na comparação entre exemplos reais e exemplos gerados artificialmente, enquanto que o AE aprende apenas a partir de dados reais<br>\n",
    "<font color='red'>(b) O espaço latente do VAE é composto por parâmetros de distribuições a partir dos quais são amostrados o exemplos a serem decodificados pelo elemento decoder, enquanto que o espaço latente do AE é aprendido sem assumir distribuições para suas dimensões.</font><br>\n",
    "(c) O espaço latente do AE é composto por parâmetros de distribuições a partir dos quais são amostrados o exemplos a serem decodificados pelo elemento decoder, enquanto que o espaço latente do VAE é aprendido sem assumir distribuições para suas dimensões, permitindo que esse seja usado também como modelo gerador.<br>\n",
    "(d) VAE aprende apenas a partir de dados reais, enquanto o AE aprende com base na comparação entre exemplos reais na entrada e exemplos gerados artificialmente em sua saída<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders convencionais tentam codificar atributos de forma discreta.<br>\n",
    "EX: Sorriso 0.95, Cor da pele 0.82...\n",
    "\n",
    "Autoencoders variacionais aprendem distribuições (seus parâmetros) de cada variável, a partir do qual se amostram valores.<br>\n",
    "EX: Sorriso, Cor da pele podem assumir variados valores, a partir da função de distribuição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Questão 2)\n",
    "\n",
    "\n",
    "Considere os métodos Generative Adversarial Networks, Denoising Autoencoder e Variational Autoencoder. Podemos dizer que esses métodos se enquadram em qual tipo de paradigma aprendizado?\n",
    "\n",
    " (a) Supervisionado<br>\n",
    " (b) Semi-supervisionado<br>\n",
    "<font color='red'> (c) Não supervisionado</font><br>\n",
    " (d) Fracamente supervisionado<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Questão 3)\n",
    "\n",
    "O objetivo principal no aprendizado de uma rede do tipo Generative Adversarial Network é\n",
    "\n",
    "<font color='red'> (a) Aprender as operações que permitem, a partir de um exemplo aleatório amostrado de uma determinada distribuição, gerar um exemplo que se assemelhe a uma amostra obtida da distribuição dos dados de treinamento</font><br>\n",
    " (b) Classificar exemplos fornecidos para a rede neural em exemplos advindos do conjunto de treinamento da base de dados de interesse, e exemplos que não pertençam a esse conjunto.<br>\n",
    " (c) Realizar uma regressão da distribuição de entrada para um espaço latente compacto e de menor dimensionalidade que a entrada, a partir do qual podemos reconstruir um exemplo de forma fiel com relação à sua dimensionalidade original<br>\n",
    " (d) Obter um modelo que aprenda a distribuição dos dados de entrada e que projete esses dados num espaço que seja robusto a possíveis ruídos em dados futuros, permitindo assim evitar ataques adversariais.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs (Generative Adversarial Networks = Redes adversárias geradoras)\n",
    "\n",
    "Adversária pois há dois componentes que \"disputam\"\n",
    "\n",
    "Geradora pois o objetivo central é aprender a gerar dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Carregue a base de dados `wine.csv`, conforme abaixo, com uma divisão hold-out utilizando os 80% exemplos iniciais para treinamento e os restantes para teste. Utilizaremos normalização min-max 0-1. Utilizaremos apenas os exemplos de treinamento obtidos nessa separação.\n",
    "\n",
    "Projete um Autoencoder para produzir um espaço de características com 5 dimensões, com as seguintes camadas:\n",
    "* Entrada (com as dimensões da base de dados)\n",
    "* Dropout de 0.25\n",
    "* Camada densa de 5 neurônios (camada de código) e ativação relu\n",
    "* Camada densa de saída (com as dimensões da base de dados) e ativação sigmoide\n",
    "\n",
    "Código é o nome que se dá à camada latente do Autoencoder, geralmente aquela contendo a maior restrição de dimensionalidade, que fornece um espaço de características compacto para os dados de entrada. Também chamamos de código as características obtidas a partir dessa camada.\n",
    "\n",
    "Inicialize as sementes `seed(1)` e `set_seed(2)` antes de instanciar o modelo, compilar e treinar.\n",
    "\n",
    "Utilize a função de custo mean absolute error (mse), otimizador Adam com taxa 0.0001, batchsize 10 e treine por 300 épocas.\n",
    "\n",
    "Após o treinamento, obtenha as características a partir da camada \"código\" do Autoencoder e grafe um scatterplot das duas primeiras características do código de treinamento, analisando visualmente a distribuição desses dados com relação das classes. Podemos identificar qual distribuição dos dados em termos da separação e sobreposição de classes?\n",
    "\n",
    "<font color='red'>(a) classe mais distintamente separada: 1, classes sobrepostas: 0 e 2</font><br>\n",
    "(b) classe mais distintamente separada: 0, classes sobrepostas: 1 e 2 <br>\n",
    "(c) classes mais distintamente separadas: 0, 1 e 2, classes sobrepostas: nenhuma<br>\n",
    "(d) classe mais distintamente separada: 2, classes sobrepostas: 0 e 1 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rif40G6wST-s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "0    14.23        1.71  2.43               15.6        127           2.80   \n",
      "1    13.20        1.78  2.14               11.2        100           2.65   \n",
      "2    13.16        2.36  2.67               18.6        101           2.80   \n",
      "3    14.37        1.95  2.50               16.8        113           3.85   \n",
      "4    13.24        2.59  2.87               21.0        118           2.80   \n",
      "\n",
      "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   OD280/OD315 of diluted wines  Proline Class  \n",
      "0                          3.92     1065   one  \n",
      "1                          3.40     1050   one  \n",
      "2                          3.17     1185   one  \n",
      "3                          3.45     1480   one  \n",
      "4                          2.93      735   one  \n",
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"wine.csv\")\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())\n",
    "classif = np.array(df['Class'].astype(\"category\").cat.codes)\n",
    "features = np.array(df.iloc[:, :-1])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplos de treinamento: 142\n",
      "Exemplos de teste: 36\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, classif, test_size=0.20, random_state=0)\n",
    "print(\"Exemplos de treinamento:\", len(X_train))\n",
    "print(\"Exemplos de teste:\", len(X_test))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_n = scaler.fit_transform(X_train)\n",
    "X_test_n = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projete um Autoencoder para produzir um espaço de características com 5 dimensões, com as seguintes camadas:<br>\n",
    "\n",
    "Entrada (com as dimensões da base de dados)<br>\n",
    "Dropout de 0.25<br>\n",
    "Camada densa de 5 neurônios (camada de código) e ativação relu<br>\n",
    "Camada densa de saída (com as dimensões da base de dados) e ativação sigmoide<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código é o nome que se dá à camada latente do Autoencoder, geralmente aquela contendo a maior restrição de dimensionalidade, que fornece um espaço de características compacto para os dados de entrada. Também chamamos de código as características obtidas a partir dessa camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim=X_train_n.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dim=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### projetar autoencoder\n",
    "def autoencoder_architecture(input_dim, code_dim):\n",
    "    \n",
    "    input_data = keras.layers.Input(shape=(input_dim,))\n",
    "    x = keras.layers.Dropout(0.25)(input_data)\n",
    "    y = keras.layers.Dense(code_dim, activation='relu', name='code')(x)\n",
    "    z = keras.layers.Dense(input_dim, activation='sigmoid')(y)\n",
    "    output = keras.models.Model(input_data, z)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialize as sementes `seed(1)` e `set_seed(2)` antes de instanciar o modelo, compilar e treinar.\n",
    "\n",
    "Utilize a função de custo mean absolute error (mse), otimizador Adam com taxa 0.0001, batchsize 10 e treine por 300 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                78        \n",
      "=================================================================\n",
      "Total params: 148\n",
      "Trainable params: 148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 2ms/step - loss: 0.0815\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0816\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0827\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0794\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 939us/step - loss: 0.0806\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0780\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0772\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0748\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0761\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0749\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0737\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0743\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0736\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0732\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0724\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0698\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0689\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0705\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0691\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0684\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0690\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0675\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0681\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0678\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0664\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0650\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0655\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0643\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0642\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0636\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0641\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0645\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0628\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0644\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0629\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0633\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0622\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0611\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0618\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0616\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0606\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0604\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0591\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0594\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0613\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0593\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0600\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0600\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0594\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0595\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0597\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0589\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0590\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0586\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0586\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0592\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0569\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0571\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0565\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0567\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0565\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0569\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0564\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0557\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0573\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0554\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0549\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0572\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0567\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0548\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0560\n",
      "Epoch 91/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0550\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0560\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0544\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0552\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0547\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0541\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0541\n",
      "Epoch 99/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0535\n",
      "Epoch 100/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0546\n",
      "Epoch 101/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0535\n",
      "Epoch 102/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0532\n",
      "Epoch 103/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0539\n",
      "Epoch 104/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0532\n",
      "Epoch 105/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0539\n",
      "Epoch 106/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0539\n",
      "Epoch 107/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0534\n",
      "Epoch 108/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0538\n",
      "Epoch 109/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0531\n",
      "Epoch 110/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 111/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 112/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 113/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0514\n",
      "Epoch 114/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0518\n",
      "Epoch 115/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 116/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 117/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0528\n",
      "Epoch 118/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0527\n",
      "Epoch 119/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0530\n",
      "Epoch 120/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0520\n",
      "Epoch 121/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0521\n",
      "Epoch 122/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0514\n",
      "Epoch 123/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0515\n",
      "Epoch 124/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 125/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 126/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0519\n",
      "Epoch 127/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0519\n",
      "Epoch 128/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0523\n",
      "Epoch 129/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 130/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0512\n",
      "Epoch 131/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 132/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 133/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0499\n",
      "Epoch 134/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 135/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0505\n",
      "Epoch 136/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 137/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0513\n",
      "Epoch 138/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0501\n",
      "Epoch 139/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 140/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0506\n",
      "Epoch 141/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 142/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0500\n",
      "Epoch 143/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0497\n",
      "Epoch 144/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0496\n",
      "Epoch 145/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0508\n",
      "Epoch 146/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 147/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 148/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0500\n",
      "Epoch 149/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0503\n",
      "Epoch 150/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 151/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0488\n",
      "Epoch 152/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 153/300\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.037 - 0s 1ms/step - loss: 0.0489\n",
      "Epoch 154/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0488\n",
      "Epoch 155/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0494\n",
      "Epoch 156/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0488\n",
      "Epoch 157/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0493\n",
      "Epoch 158/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 159/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0493\n",
      "Epoch 160/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0501\n",
      "Epoch 161/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 162/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 163/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 164/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0482\n",
      "Epoch 165/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 166/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0478\n",
      "Epoch 167/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0478\n",
      "Epoch 168/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0479\n",
      "Epoch 169/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0490\n",
      "Epoch 170/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 171/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0467\n",
      "Epoch 172/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0467\n",
      "Epoch 173/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0488\n",
      "Epoch 174/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0473\n",
      "Epoch 175/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0471\n",
      "Epoch 176/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0467\n",
      "Epoch 177/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 178/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0473\n",
      "Epoch 179/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0480\n",
      "Epoch 180/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0461\n",
      "Epoch 181/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0473\n",
      "Epoch 182/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0469\n",
      "Epoch 183/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0470\n",
      "Epoch 184/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 185/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 186/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0478\n",
      "Epoch 187/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0462\n",
      "Epoch 188/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0475\n",
      "Epoch 189/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0466\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0474\n",
      "Epoch 191/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 192/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0457\n",
      "Epoch 193/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0466\n",
      "Epoch 194/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0455\n",
      "Epoch 195/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0458\n",
      "Epoch 196/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0455\n",
      "Epoch 197/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 198/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0463\n",
      "Epoch 199/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0460\n",
      "Epoch 200/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0464\n",
      "Epoch 201/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0471\n",
      "Epoch 202/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0466\n",
      "Epoch 203/300\n",
      "15/15 [==============================] - 0s 413us/step - loss: 0.0458\n",
      "Epoch 204/300\n",
      "15/15 [==============================] - 0s 904us/step - loss: 0.0449\n",
      "Epoch 205/300\n",
      "15/15 [==============================] - 0s 686us/step - loss: 0.0450\n",
      "Epoch 206/300\n",
      "15/15 [==============================] - 0s 810us/step - loss: 0.0448\n",
      "Epoch 207/300\n",
      "15/15 [==============================] - 0s 175us/step - loss: 0.0459\n",
      "Epoch 208/300\n",
      "15/15 [==============================] - 0s 710us/step - loss: 0.0459\n",
      "Epoch 209/300\n",
      "15/15 [==============================] - 0s 939us/step - loss: 0.0451\n",
      "Epoch 210/300\n",
      "15/15 [==============================] - 0s 311us/step - loss: 0.0451\n",
      "Epoch 211/300\n",
      "15/15 [==============================] - 0s 267us/step - loss: 0.0449\n",
      "Epoch 212/300\n",
      "15/15 [==============================] - 0s 564us/step - loss: 0.0445\n",
      "Epoch 213/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0445\n",
      "Epoch 214/300\n",
      "15/15 [==============================] - 0s 918us/step - loss: 0.0455\n",
      "Epoch 215/300\n",
      "15/15 [==============================] - 0s 783us/step - loss: 0.0450\n",
      "Epoch 216/300\n",
      "15/15 [==============================] - 0s 320us/step - loss: 0.0446\n",
      "Epoch 217/300\n",
      "15/15 [==============================] - 0s 846us/step - loss: 0.0460\n",
      "Epoch 218/300\n",
      "15/15 [==============================] - 0s 628us/step - loss: 0.0439\n",
      "Epoch 219/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0447\n",
      "Epoch 220/300\n",
      "15/15 [==============================] - 0s 937us/step - loss: 0.0450\n",
      "Epoch 221/300\n",
      "15/15 [==============================] - 0s 834us/step - loss: 0.0443\n",
      "Epoch 222/300\n",
      "15/15 [==============================] - 0s 260us/step - loss: 0.0447\n",
      "Epoch 223/300\n",
      "15/15 [==============================] - 0s 369us/step - loss: 0.0453\n",
      "Epoch 224/300\n",
      "15/15 [==============================] - 0s 621us/step - loss: 0.0442\n",
      "Epoch 225/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0450\n",
      "Epoch 226/300\n",
      "15/15 [==============================] - 0s 925us/step - loss: 0.0438\n",
      "Epoch 227/300\n",
      "15/15 [==============================] - 0s 837us/step - loss: 0.0445\n",
      "Epoch 228/300\n",
      "15/15 [==============================] - 0s 835us/step - loss: 0.0434\n",
      "Epoch 229/300\n",
      "15/15 [==============================] - 0s 796us/step - loss: 0.0442\n",
      "Epoch 230/300\n",
      "15/15 [==============================] - 0s 761us/step - loss: 0.0428\n",
      "Epoch 231/300\n",
      "15/15 [==============================] - 0s 839us/step - loss: 0.0429\n",
      "Epoch 232/300\n",
      "15/15 [==============================] - 0s 831us/step - loss: 0.0427\n",
      "Epoch 233/300\n",
      "15/15 [==============================] - 0s 833us/step - loss: 0.0434\n",
      "Epoch 234/300\n",
      "15/15 [==============================] - 0s 381us/step - loss: 0.0433\n",
      "Epoch 235/300\n",
      "15/15 [==============================] - 0s 473us/step - loss: 0.0423\n",
      "Epoch 236/300\n",
      "15/15 [==============================] - 0s 669us/step - loss: 0.0443\n",
      "Epoch 237/300\n",
      "15/15 [==============================] - 0s 721us/step - loss: 0.0435\n",
      "Epoch 238/300\n",
      "15/15 [==============================] - 0s 884us/step - loss: 0.0433\n",
      "Epoch 239/300\n",
      "15/15 [==============================] - 0s 983us/step - loss: 0.0444\n",
      "Epoch 240/300\n",
      "15/15 [==============================] - 0s 759us/step - loss: 0.0437\n",
      "Epoch 241/300\n",
      "15/15 [==============================] - 0s 410us/step - loss: 0.0426\n",
      "Epoch 242/300\n",
      "15/15 [==============================] - 0s 839us/step - loss: 0.0427\n",
      "Epoch 243/300\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.0425\n",
      "Epoch 244/300\n",
      "15/15 [==============================] - 0s 780us/step - loss: 0.0430\n",
      "Epoch 245/300\n",
      "15/15 [==============================] - 0s 749us/step - loss: 0.0431\n",
      "Epoch 246/300\n",
      "15/15 [==============================] - 0s 646us/step - loss: 0.0431\n",
      "Epoch 247/300\n",
      "15/15 [==============================] - 0s 446us/step - loss: 0.0440\n",
      "Epoch 248/300\n",
      "15/15 [==============================] - 0s 488us/step - loss: 0.0413\n",
      "Epoch 249/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0428\n",
      "Epoch 250/300\n",
      "15/15 [==============================] - 0s 861us/step - loss: 0.0420\n",
      "Epoch 251/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0422\n",
      "Epoch 252/300\n",
      "15/15 [==============================] - 0s 492us/step - loss: 0.0420\n",
      "Epoch 253/300\n",
      "15/15 [==============================] - 0s 470us/step - loss: 0.0427\n",
      "Epoch 254/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0416\n",
      "Epoch 255/300\n",
      "15/15 [==============================] - 0s 859us/step - loss: 0.0429\n",
      "Epoch 256/300\n",
      "15/15 [==============================] - 0s 597us/step - loss: 0.0427\n",
      "Epoch 257/300\n",
      "15/15 [==============================] - 0s 748us/step - loss: 0.0424\n",
      "Epoch 258/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0406\n",
      "Epoch 259/300\n",
      "15/15 [==============================] - 0s 948us/step - loss: 0.0427\n",
      "Epoch 260/300\n",
      "15/15 [==============================] - 0s 433us/step - loss: 0.0414\n",
      "Epoch 261/300\n",
      "15/15 [==============================] - 0s 493us/step - loss: 0.0408\n",
      "Epoch 262/300\n",
      "15/15 [==============================] - 0s 701us/step - loss: 0.0414\n",
      "Epoch 263/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0415\n",
      "Epoch 264/300\n",
      "15/15 [==============================] - 0s 798us/step - loss: 0.0411\n",
      "Epoch 265/300\n",
      "15/15 [==============================] - 0s 631us/step - loss: 0.0417\n",
      "Epoch 266/300\n",
      "15/15 [==============================] - 0s 466us/step - loss: 0.0419\n",
      "Epoch 267/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0405\n",
      "Epoch 268/300\n",
      "15/15 [==============================] - 0s 982us/step - loss: 0.0403\n",
      "Epoch 269/300\n",
      "15/15 [==============================] - 0s 560us/step - loss: 0.0419\n",
      "Epoch 270/300\n",
      "15/15 [==============================] - 0s 781us/step - loss: 0.0414\n",
      "Epoch 271/300\n",
      "15/15 [==============================] - 0s 616us/step - loss: 0.0406\n",
      "Epoch 272/300\n",
      "15/15 [==============================] - 0s 524us/step - loss: 0.0397\n",
      "Epoch 273/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0399\n",
      "Epoch 274/300\n",
      "15/15 [==============================] - 0s 753us/step - loss: 0.0402\n",
      "Epoch 275/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0409\n",
      "Epoch 276/300\n",
      "15/15 [==============================] - 0s 643us/step - loss: 0.0428\n",
      "Epoch 277/300\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.0407\n",
      "Epoch 278/300\n",
      "15/15 [==============================] - 0s 613us/step - loss: 0.0418\n",
      "Epoch 279/300\n",
      "15/15 [==============================] - 0s 485us/step - loss: 0.0404\n",
      "Epoch 280/300\n",
      "15/15 [==============================] - 0s 673us/step - loss: 0.0394\n",
      "Epoch 281/300\n",
      "15/15 [==============================] - 0s 912us/step - loss: 0.0426\n",
      "Epoch 282/300\n",
      "15/15 [==============================] - 0s 497us/step - loss: 0.0402\n",
      "Epoch 283/300\n",
      "15/15 [==============================] - 0s 713us/step - loss: 0.0401\n",
      "Epoch 284/300\n",
      "15/15 [==============================] - 0s 579us/step - loss: 0.0406\n",
      "Epoch 285/300\n",
      "15/15 [==============================] - 0s 722us/step - loss: 0.0408\n",
      "Epoch 286/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0396\n",
      "Epoch 287/300\n",
      "15/15 [==============================] - 0s 914us/step - loss: 0.0392\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 577us/step - loss: 0.0415\n",
      "Epoch 289/300\n",
      "15/15 [==============================] - 0s 815us/step - loss: 0.0401\n",
      "Epoch 290/300\n",
      "15/15 [==============================] - 0s 508us/step - loss: 0.0393\n",
      "Epoch 291/300\n",
      "15/15 [==============================] - 0s 320us/step - loss: 0.0400\n",
      "Epoch 292/300\n",
      "15/15 [==============================] - 0s 541us/step - loss: 0.0395\n",
      "Epoch 293/300\n",
      "15/15 [==============================] - 0s 769us/step - loss: 0.0396\n",
      "Epoch 294/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0398\n",
      "Epoch 295/300\n",
      "15/15 [==============================] - 0s 382us/step - loss: 0.0395\n",
      "Epoch 296/300\n",
      "15/15 [==============================] - 0s 261us/step - loss: 0.0415\n",
      "Epoch 297/300\n",
      "15/15 [==============================] - 0s 442us/step - loss: 0.0402\n",
      "Epoch 298/300\n",
      "15/15 [==============================] - 0s 495us/step - loss: 0.0399\n",
      "Epoch 299/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0387\n",
      "Epoch 300/300\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0391\n"
     ]
    }
   ],
   "source": [
    "### definir sementes, instanciar AE, compilar e treinar\n",
    "epochs = 300\n",
    "batch_size = 10\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "# instanciar AE\n",
    "autoencoder = autoencoder_architecture(input_dim=X_train_n.shape[1], code_dim=code_dim)\n",
    "autoencoder.summary()\n",
    "\n",
    "# compilar AE\n",
    "autoencoder.compile(loss='mse',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.0001))\n",
    "\n",
    "# treinar AE\n",
    "hist_ae = autoencoder.fit(X_train_n, X_train_n, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obter características dos dados de treinamento (code_train) a partir da camada de código do autoencoder\n",
    "code_modelenc = keras.models.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('code').output)\n",
    "code_train = np.asarray(code_modelenc.predict(X_train_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Exibir as duas primeiras caracerísticas para análise visual\n",
    "size_sample = len(X_train)\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(code_train[:size_sample,0], code_train[:size_sample,1], c=y_train[:size_sample], alpha=0.75, cmap=\"jet\")\n",
    "legend1 = ax.legend(*scatter.legend_elements(), loc=\"lower right\", title=\"Classes\")\n",
    "ax.add_artist(legend1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifQGbqS05Rts"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "\n",
    "Carregue a base de dados `wine.csv`, conforme abaixo, com uma divisão hold-out utilizando os 80% exemplos iniciais para treinamento e os restantes para teste. \n",
    "\n",
    "Projete um Autoencoder profundo para produzir uma projeção em 3 dimensões, com as seguintes camadas:\n",
    "* Entrada (com as dimensões originais da base de dados)\n",
    "* Camada densas com 8 neurônios, ativação relu\n",
    "* Camada densa com 3 neurônios (camada de código), ativação relu\n",
    "* Dropout de 1/3.0 (um terço)\n",
    "* Camada densas com 8 neurônios, ativação relu\n",
    "* Camada densa de saída (com as dimensões originais da base de dados), ativação sigmóide\n",
    "\n",
    "Inicialize as sementes `seed(1)` e `set_seed(2)` antes de instanciar o modelo, compilar e treinar (com o conjunto de treinamento).\n",
    "\n",
    "Utilize a função de custo mean squared error (MSE), otimizador Adam com taxa 0.0001, batchsize 10 e treine por 300 épocas.\n",
    "\n",
    "Após o treinamento:\n",
    "1. Calcule o MSE (do autoencoder) no conjunto de teste\n",
    "2. Obtenha as características a partir do código de 3 dimensões para o conjunto de treinamento e de teste. Treine um classificador SVM (utilizando `SVC(C=0.5, random_state=1, kernel=\"rbf\")`) com o código de treinamento (3 dimensões). Calcule a acurácia obtida pelo SVM no conjunto de teste (utilizando as características obtidas a partir do autoencoder).\n",
    "\n",
    "Os valores observados de MSE no teste do autoencoder, e acurácia de classificação SVM no teste estão em qual intervalo?\n",
    "\n",
    "(a) MSE =[0.01, 0.08]; Acurácia = [0.73, 0.82] <br>\n",
    "<font color='red'>(b) MSE =[0.01, 0.08]; Acurácia = [0.87, 0.98] </font><br>\n",
    "(c) MSE =[0.10, 0.16]; Acurácia = [0.73, 0.82] <br>\n",
    "(d) MSE =[0.10, 0.16]; Acurácia = [0.87, 0.98] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplos de treinamento: 142\n",
      "Exemplos de teste: 36\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, classif, test_size=0.20, random_state=0)\n",
    "print(\"Exemplos de treinamento:\", len(X_train))\n",
    "print(\"Exemplos de teste:\", len(X_test))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_n = scaler.fit_transform(X_train)\n",
    "X_test_n = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projete um Autoencoder profundo para produzir uma projeção em 3 dimensões, com as seguintes camadas:\n",
    "* Entrada (com as dimensões originais da base de dados)\n",
    "* Camada densas com 8 neurônios, ativação relu\n",
    "* Camada densa com 3 neurônios (camada de código), ativação relu\n",
    "* Dropout de 1/3.0 (um terço)\n",
    "* Camada densas com 8 neurônios, ativação relu\n",
    "* Camada densa de saída (com as dimensões originais da base de dados), ativação sigmóide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(input_dim)\n",
    "print(code_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### projetar autoencoder\n",
    "def deep_autoencoder(input_dim, code_dim):\n",
    "    \n",
    "    input_data = keras.layers.Input(shape=(input_dim,))\n",
    "    den1 = keras.layers.Dense(8, activation='relu')(input_data)\n",
    "    den2 = keras.layers.Dense(3, activation='relu', name='code')(den1)\n",
    "    drop = keras.layers.Dropout(1/3.0)(den2)\n",
    "    den3 = keras.layers.Dense(8, activation='relu')(drop)\n",
    "    den4 = keras.layers.Dense(input_dim, activation='sigmoid')(den3)\n",
    "    output = keras.models.Model(input_data, den4)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialize as sementes `seed(1)` e `set_seed(2)` antes de instanciar o modelo, compilar e treinar (com o conjunto de treinamento).\n",
    "\n",
    "Utilize a função de custo mean squared error (MSE), otimizador Adam com taxa 0.0001, batchsize 10 e treine por 300 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                117       \n",
      "=================================================================\n",
      "Total params: 288\n",
      "Trainable params: 288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 18ms/step - loss: 0.0602 - val_loss: 0.0599\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0595\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0594\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0592\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0591\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0590\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0589\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0588\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0587\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0587\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0586\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0585\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0584\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0582 - val_loss: 0.0583\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0580 - val_loss: 0.0582\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0580 - val_loss: 0.0581\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0578 - val_loss: 0.0580\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0577 - val_loss: 0.0579\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0576 - val_loss: 0.0578\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0575 - val_loss: 0.0577\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.0573 - val_loss: 0.0576\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0572 - val_loss: 0.0575\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0571 - val_loss: 0.0574\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0569 - val_loss: 0.0573\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0572\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0571\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0565 - val_loss: 0.0570\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0569\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0568\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0567\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0566\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0561 - val_loss: 0.0565\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0564\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0563\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0562\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0561\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0560\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0559\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0558\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.0557\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0556\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0555\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0554\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0553\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0552\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0545 - val_loss: 0.0551\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0550\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0549\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0548\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0547\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0546\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0545\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0544\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0544\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0543\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.0542\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0541\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0540\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.0539\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0538\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0537\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0536\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0535\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0534\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0533\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0532\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0531\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0530\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0529\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0528\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0527\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.048 - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0525\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0524\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0523\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0522\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0521\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0521\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0520\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0519\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0518\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0517\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0516\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0515\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0514\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0506 - val_loss: 0.0513\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0497 - val_loss: 0.0512\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0504 - val_loss: 0.0511\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0510\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0509\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0508\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0507\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0506\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0505\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0504\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0503\n",
      "Epoch 99/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0502\n",
      "Epoch 100/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0502\n",
      "Epoch 101/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0501\n",
      "Epoch 102/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0500\n",
      "Epoch 103/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0499\n",
      "Epoch 104/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0498\n",
      "Epoch 105/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0497\n",
      "Epoch 106/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0496\n",
      "Epoch 107/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0495\n",
      "Epoch 108/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0494\n",
      "Epoch 109/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0494\n",
      "Epoch 110/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0493\n",
      "Epoch 111/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0492\n",
      "Epoch 112/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0491\n",
      "Epoch 113/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0490\n",
      "Epoch 114/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0489\n",
      "Epoch 115/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0489\n",
      "Epoch 116/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0488\n",
      "Epoch 117/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0487\n",
      "Epoch 118/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0486\n",
      "Epoch 119/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0485\n",
      "Epoch 120/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0484\n",
      "Epoch 121/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0483\n",
      "Epoch 122/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0483\n",
      "Epoch 123/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.0482\n",
      "Epoch 124/300\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0473 - val_loss: 0.0481\n",
      "Epoch 125/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0466 - val_loss: 0.0480\n",
      "Epoch 126/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0479\n",
      "Epoch 127/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0478\n",
      "Epoch 128/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0477\n",
      "Epoch 129/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0477\n",
      "Epoch 130/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0476\n",
      "Epoch 131/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0475\n",
      "Epoch 132/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0474\n",
      "Epoch 133/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0473\n",
      "Epoch 134/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 135/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 136/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0471\n",
      "Epoch 137/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0470\n",
      "Epoch 138/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0469\n",
      "Epoch 139/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0468\n",
      "Epoch 140/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0467\n",
      "Epoch 141/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0467\n",
      "Epoch 142/300\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.042 - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0466\n",
      "Epoch 143/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0465\n",
      "Epoch 144/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0464\n",
      "Epoch 145/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0464\n",
      "Epoch 146/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0463\n",
      "Epoch 147/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.0462\n",
      "Epoch 148/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0461\n",
      "Epoch 149/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0454 - val_loss: 0.0460\n",
      "Epoch 150/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0460\n",
      "Epoch 151/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0441 - val_loss: 0.0459\n",
      "Epoch 152/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0453 - val_loss: 0.0458\n",
      "Epoch 153/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0463 - val_loss: 0.0457\n",
      "Epoch 154/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0438 - val_loss: 0.0457\n",
      "Epoch 155/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0456\n",
      "Epoch 156/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0455\n",
      "Epoch 157/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0451 - val_loss: 0.0454\n",
      "Epoch 158/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0452 - val_loss: 0.0453\n",
      "Epoch 159/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0452\n",
      "Epoch 160/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 161/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.0451\n",
      "Epoch 162/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0450\n",
      "Epoch 163/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0449\n",
      "Epoch 164/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0448\n",
      "Epoch 165/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0452 - val_loss: 0.0447\n",
      "Epoch 166/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0451 - val_loss: 0.0447\n",
      "Epoch 167/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0439 - val_loss: 0.0446\n",
      "Epoch 168/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.0445\n",
      "Epoch 169/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.0444\n",
      "Epoch 170/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.0444\n",
      "Epoch 171/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0443\n",
      "Epoch 172/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.0442\n",
      "Epoch 173/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0441\n",
      "Epoch 174/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.0440\n",
      "Epoch 175/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.0440\n",
      "Epoch 176/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.0439\n",
      "Epoch 177/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0438 - val_loss: 0.0438\n",
      "Epoch 178/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0432 - val_loss: 0.0437\n",
      "Epoch 179/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0436\n",
      "Epoch 180/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0435\n",
      "Epoch 181/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0438 - val_loss: 0.0435\n",
      "Epoch 182/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0440 - val_loss: 0.0434\n",
      "Epoch 183/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0444 - val_loss: 0.0433\n",
      "Epoch 184/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0428 - val_loss: 0.0432\n",
      "Epoch 185/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0436 - val_loss: 0.0431\n",
      "Epoch 186/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0429 - val_loss: 0.0430\n",
      "Epoch 187/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0439 - val_loss: 0.0429\n",
      "Epoch 188/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0426 - val_loss: 0.0429\n",
      "Epoch 189/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0427\n",
      "Epoch 190/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0426\n",
      "Epoch 191/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0430 - val_loss: 0.0426\n",
      "Epoch 192/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0433 - val_loss: 0.0425\n",
      "Epoch 193/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.0424\n",
      "Epoch 194/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0423\n",
      "Epoch 195/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0422\n",
      "Epoch 196/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0421\n",
      "Epoch 197/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0420\n",
      "Epoch 198/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0419\n",
      "Epoch 199/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0418\n",
      "Epoch 200/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0417\n",
      "Epoch 201/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.0416\n",
      "Epoch 202/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0415\n",
      "Epoch 203/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0426 - val_loss: 0.0415\n",
      "Epoch 204/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0414\n",
      "Epoch 205/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0413\n",
      "Epoch 206/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.0412\n",
      "Epoch 207/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0411\n",
      "Epoch 208/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0410\n",
      "Epoch 209/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0409\n",
      "Epoch 210/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0408\n",
      "Epoch 211/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0408\n",
      "Epoch 212/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0407\n",
      "Epoch 213/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0406\n",
      "Epoch 214/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0417 - val_loss: 0.0405\n",
      "Epoch 215/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0420 - val_loss: 0.0404\n",
      "Epoch 216/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0403\n",
      "Epoch 217/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 218/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0405 - val_loss: 0.0401\n",
      "Epoch 219/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.0400\n",
      "Epoch 220/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0405 - val_loss: 0.0399\n",
      "Epoch 221/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0398\n",
      "Epoch 222/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0397\n",
      "Epoch 223/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.0396\n",
      "Epoch 224/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0395\n",
      "Epoch 225/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0401 - val_loss: 0.0394\n",
      "Epoch 226/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0393\n",
      "Epoch 227/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0405 - val_loss: 0.0392\n",
      "Epoch 228/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0413 - val_loss: 0.0392\n",
      "Epoch 229/300\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0402 - val_loss: 0.0391\n",
      "Epoch 230/300\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0411 - val_loss: 0.0390\n",
      "Epoch 231/300\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0389\n",
      "Epoch 232/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0410 - val_loss: 0.0388\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.0387\n",
      "Epoch 234/300\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0404 - val_loss: 0.0386\n",
      "Epoch 235/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0407 - val_loss: 0.0385\n",
      "Epoch 236/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0399 - val_loss: 0.0385\n",
      "Epoch 237/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0394 - val_loss: 0.0384\n",
      "Epoch 238/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0383\n",
      "Epoch 239/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0397 - val_loss: 0.0382\n",
      "Epoch 240/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0394 - val_loss: 0.0381\n",
      "Epoch 241/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.0381\n",
      "Epoch 242/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0380\n",
      "Epoch 243/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0379\n",
      "Epoch 244/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0401 - val_loss: 0.0378\n",
      "Epoch 245/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.0378\n",
      "Epoch 246/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0396 - val_loss: 0.0377\n",
      "Epoch 247/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0376\n",
      "Epoch 248/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0375\n",
      "Epoch 249/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0375\n",
      "Epoch 250/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0393 - val_loss: 0.0374\n",
      "Epoch 251/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0392 - val_loss: 0.0373\n",
      "Epoch 252/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0373\n",
      "Epoch 253/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0390 - val_loss: 0.0372\n",
      "Epoch 254/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0371\n",
      "Epoch 255/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0370\n",
      "Epoch 256/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0369\n",
      "Epoch 257/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0369\n",
      "Epoch 258/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0368\n",
      "Epoch 259/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0367\n",
      "Epoch 260/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0367\n",
      "Epoch 261/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0366\n",
      "Epoch 262/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0365\n",
      "Epoch 263/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0365\n",
      "Epoch 264/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0364\n",
      "Epoch 265/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0368 - val_loss: 0.0363\n",
      "Epoch 266/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.0362\n",
      "Epoch 267/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0362\n",
      "Epoch 268/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0361\n",
      "Epoch 269/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0361\n",
      "Epoch 270/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0360\n",
      "Epoch 271/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0360\n",
      "Epoch 272/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0396 - val_loss: 0.0359\n",
      "Epoch 273/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0359\n",
      "Epoch 274/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.0358\n",
      "Epoch 275/300\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0388 - val_loss: 0.0357\n",
      "Epoch 276/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0376 - val_loss: 0.0357\n",
      "Epoch 277/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0356\n",
      "Epoch 278/300\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0355\n",
      "Epoch 279/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0355\n",
      "Epoch 280/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0354\n",
      "Epoch 281/300\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0381 - val_loss: 0.0353\n",
      "Epoch 282/300\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0370 - val_loss: 0.0353\n",
      "Epoch 283/300\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0352\n",
      "Epoch 284/300\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0385 - val_loss: 0.0352\n",
      "Epoch 285/300\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.0384 - val_loss: 0.0351\n",
      "Epoch 286/300\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0382 - val_loss: 0.0351\n",
      "Epoch 287/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0367 - val_loss: 0.0350\n",
      "Epoch 288/300\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0388 - val_loss: 0.0349\n",
      "Epoch 289/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0374 - val_loss: 0.0349\n",
      "Epoch 290/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0380 - val_loss: 0.0349\n",
      "Epoch 291/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.0348\n",
      "Epoch 292/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.0347\n",
      "Epoch 293/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.0347\n",
      "Epoch 294/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0371 - val_loss: 0.0346\n",
      "Epoch 295/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.0346\n",
      "Epoch 296/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0354 - val_loss: 0.0345\n",
      "Epoch 297/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0344\n",
      "Epoch 298/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0344\n",
      "Epoch 299/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.0343\n",
      "Epoch 300/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0366 - val_loss: 0.0343\n"
     ]
    }
   ],
   "source": [
    "### definir sementes, instanciar AE, compilar e treinar\n",
    "epochs = 300\n",
    "batch_size = 10\n",
    "\n",
    "seed(1)\n",
    "set_seed(2)\n",
    "\n",
    "# instanciar AE\n",
    "autoencoder = deep_autoencoder(input_dim=X_train_n.shape[1], code_dim=code_dim)\n",
    "autoencoder.summary()\n",
    "\n",
    "# compilar AE\n",
    "autoencoder.compile(loss='mse',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.0001))\n",
    "\n",
    "# treinar AE\n",
    "hist_ae = autoencoder.fit(X_train_n, X_train_n, validation_data=(X_test_n,X_test_n), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinamento:\n",
    "1. Calcule o MSE (do autoencoder) no conjunto de teste\n",
    "2. Obtenha as características a partir do código de 3 dimensões para o conjunto de treinamento e de teste. Treine um classificador SVM (utilizando `SVC(C=0.5, random_state=1, kernel=\"rbf\")`) com o código de treinamento (3 dimensões). Calcule a acurácia obtida pelo SVM no conjunto de teste (utilizando as características obtidas a partir do autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_treino no treinamento: 0.05 \n"
     ]
    }
   ],
   "source": [
    "# Obtendo o MSE médio para o conjunto de treino no treinamento\n",
    "MSE_treino = np.mean(hist_ae.history['loss'])\n",
    "print('MSE_treino no treinamento: %.2f ' % (MSE_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_teste no treinamento: 0.05 \n"
     ]
    }
   ],
   "source": [
    "# Obtendo o MSE médio para o conjunto de teste no treinamento\n",
    "MSE_teste = np.mean(hist_ae.history['val_loss'])\n",
    "print('MSE_teste no treinamento: %.2f ' % (MSE_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_teste após o treinamento: 0.03 \n"
     ]
    }
   ],
   "source": [
    "# Obtendo o MSE para o conjunto de teste após o treinamento\n",
    "score = autoencoder.evaluate(X_test_n,X_test_n, verbose=0)\n",
    "print('MSE_teste após o treinamento: %.2f ' % (score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando score...\n",
      "\n",
      "score: 0.94 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### obter características dos dados de treinamento (code_train) a partir da camada de código do autoencoder\n",
    "code_modelenc = keras.models.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('code').output)\n",
    "code_train = np.asarray(code_modelenc.predict(X_train_n))\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "clf = svm.SVC(C=0.5, random_state=1, kernel=\"rbf\")\n",
    "clf.fit(code_train, y_train)\n",
    "code_test = np.asarray(code_modelenc.predict(X_test_n))\n",
    "\n",
    "# Score: Return the mean accuracy on the given test data and labels.\n",
    "print('Calculando score...')\n",
    "score = clf.score(code_test, y_test)\n",
    "print('\\nscore: %.2f ' % (score))\n",
    "\n",
    "disp = plot_confusion_matrix(clf, code_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Avaliacao_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
