{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo I - Deep Learning e redes do tipo Perceptron</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "USP\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Exercícios Essenciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 1)\n",
    "\n",
    "As redes neurais artificiais passaram por um chamado \"inverno\" em que recebiam pouca atenção da academia e do mercado quando comparado aos sistemas especialistas. Porque isso mudou em meados de 2010?\n",
    "\n",
    " (a) Devido a descobertas da inteligência artificial em 2012 que revolucionou a área<br>\n",
    " <font color='red'>(b) Trabalhos científicos mostraram que a utilização de grandes bases de dados anotadas e o uso de placas gráficas permitiam treinar modelos com baixo erro de classificação</font><br>\n",
    " (c) Devido a melhoria dos sistemas computacionais, incluindo melhores processadores (CPUs), maior memória principal disponível (RAM) e placas gráficas (GPUs)<br>\n",
    " (d) Pois foi nessa época em que a área de ciência de dados tomou destaque, devido a grande quantidade de dados disponível (big data)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O uso de processamento gráfico paralelo (GPU) permitiu o uso de grandes quantidades de dados para treinamento e a consequentemente a obtenção de melhores resultados com modelos de redes neurais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercício 2)\n",
    "\n",
    "Seja $\\mathbf{x} \\in X$ um vetor com informações sobre perfis de clientes de um e-commerce, incluindo: data de nascimento, cidade, quantidade de pedidos realizados nos últimos 12 meses, total em reais das compras, entre outros. Desejamos obter um modelo que seja capaz de receber por entrada uma instância de $X$ e inferir a probabilidade $y$ de um cliente realizar uma compra no próximo mês. Considere duas formulações conforme abaixo:\n",
    "\n",
    "1. Modelo A: $f(\\mathbf{x}) = \\hat{y}$\n",
    "2. Modelo B: $$\\begin{align}\n",
    "g(\\mathbf{x}) &= \\mathbf{r},\\\\\n",
    "h(\\mathbf{r}) &= \\mathbf{s},\\\\\n",
    "i(\\mathbf{s}) &= \\mathbf{w},\\\\\n",
    "f(\\mathbf{w}) &= \\hat{y}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "O que podemos dizer sobre A e B?\n",
    "\n",
    "(a) A é um classificador linear e B é um regressor multi-estágio<br>\n",
    "(b) apenas B é uma formulação de aprendizado de máquina, enquanto A não pode ser considerado aprendizado de máquina<br>\n",
    "(c) A é um classificador linear como o Perceptron, enquanto B é uma rede neural profunda<br>\n",
    "<font color='red'>(d) A é uma formulação rasa, enquanto que B é uma formulação profunda para aprendizado de máquina</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 3)\n",
    "\n",
    "Seja $\\mathbf{x}$ um vetor de entrada e $s$ um valor de saída de um neurônio de uma rede neural baseada em Perceptron. O processamento pode ser escrito na forma:\n",
    "\n",
    "$f(\\mathbf{x}) = a(\\mathbf{w}^t\\mathbf{x}+b) = s$,\n",
    "\n",
    "sendo que $a()$ é a função de ativação. Sabendo que a entrada tem $d$ dimensões, quais são as dimensões das variáveis $w$ e $b$?\n",
    "\n",
    "<font color='red'>(a) $w$ é um vetor com $d$ dimensões, enquanto $b$ é escalar possuindo uma dimensão</font><br>\n",
    "(b) $w$ é um vetor com 2 dimensões, enquanto $b$ é escalar possuindo uma dimensão<br>\n",
    "(c) $w$ é escalar com 1 dimensão, enquanto $b$ é o vetor bias cujo número de dimensões é igual ao número de classes do problema<br>\n",
    "(d) $w$ é um vetor com $d-1$ dimensões, enquanto $b$ é bias e portanto possui apenas 1 dimensão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w é o vetor de pesos que multiplicarão cada atributo, portanto sua dimensão deve ser igual à dos atributos, portanto e dimensões<br>\n",
    "b é um escalar(bias)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 4)\n",
    "\n",
    "Seja $\\mathbf{x}$ um vetor de entrada e $\\mathbf{s}$ um vetor de saída de uma camada de rede neural baseada em Perceptron. O processamento pode ser escrito na forma:\n",
    "\n",
    "$f(\\mathbf{x}) = a(W\\mathbf{x}+\\mathbf{b}) = \\mathbf{s}$,\n",
    "\n",
    "sendo que $a()$ é a função de ativação. Sabendo que a entrada tem $d$ dimensões e a saída tem $z$ dimensões, quais são as dimensões das variáveis $W$ e $b$ e quantos neurônios possui essa camada?\n",
    "\n",
    "(a) são $d$ neurônios, sendo que $W$ possui $z \\times d$, e $b$ possui $d$ dimensões<br>\n",
    "(b) são $d \\times z$ neurônios, sendo que $W$ possui $z \\times d$, e $b$ possui $d$ dimensões<br>\n",
    "<font color='red'>(c) são $z$ neurônios, sendo que $W$ possui $z \\times d$, e $b$ possui $z$ dimensões</font><br>\n",
    "(d) são $z$ neurônios, sendo que $W$ possui $d$, e $b$ possui $z$ dimensões\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário 1 neurônio para cada dimensão de saída, portanto, são z neurônios.<br>\n",
    "W é o vetor de pesos, portanto d dimensões multiplicada pelo número de dimensões de saída.<br>\n",
    "b (bias) é um escalar possuindo 1 dimensão para cada dimensão de saída, portanto, z dimensões.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 5)\n",
    "\n",
    "Qual a diferença entre as funções de ativação *sigmoide* e *softmax* aplicadas a uma camada de uma rede neural?\n",
    "\n",
    "(a) a sigmóide produz como saída vetores cuja somatória é 1 e que podem ser interpretados como uma distribuição de probabilidade, enquanto a softmax comprime os valores da saída entre 0 e 1 <br>\n",
    "(b) a sigmóide produz como saída vetores cujos valores estão entre -1 e 1, enquanto a softmax comprime os valores da saída entre 0 e 1<br>\n",
    "<font color='red'>(c) a sigmóide comprime os valores da saída entre 0 e 1, enquanto a softmax produz como saída vetores cuja somatória é 1 e que podem ser interpretados como uma distribuição de probabilidade</font><br>\n",
    "(d) a sigmóide produz como saída vetores cujos valores individuais estão entre 0 e 1 utilizando uma função suave, enquanto a softmax produz vetores no formato one-hot-encoding compatíveis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmóide é uma função de ativação que transforma um sinal de entrada em um sinal de saída entre 0 e 1.<br>\n",
    "Softmax é classificador que normaliza a saída de forma a somar 1, permitindo interpretar cada valor como sendo uma probabilidade e a saída pode ser descrita como uma função de distribuição de probabilidades de uma determinada classe.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 6)\n",
    "\n",
    "Utilizando a biblioteca Keras, formule um modelo de rede neural sequencial, do tipo MLP, cuja entrada seja preparada para receber um vetor de 100 dimensões e que possua 2 camadas ocultas, cada uma com 50 neurônios, e 1 camada de saída, com 3 neurônios e função de ativação softmax.\n",
    "\n",
    "Quantos parâmetros, no total, essa rede possui?\n",
    "\n",
    "(a) 203<br>\n",
    "(b) 10303<br>\n",
    "(c) 7651<br>\n",
    "<font color='red'>(d) 7753</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,753\n",
      "Trainable params: 7,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### seu codigo\n",
    "from tensorflow import keras\n",
    "\n",
    "model1 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(50, activation=\"relu\", input_shape=(100,)),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O total de parâmetros a serem estimados é a soma de cada camada: 5050+2550+153 = 7753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 7)\n",
    "\n",
    "Considerando que temos uma base de dados de treinamento com 8000 exemplos. Definindo o tamanho do lote (minibatch size) como sendo 50, quantas iterações o algoritmo backpropagation deverá executar, adaptando os parâmetros da rede, para completar 5 épocas?\n",
    "\n",
    "<font color='red'>(a) 800</font><br>\n",
    "(a) 160<br>\n",
    "(b) 801<br>\n",
    "(c) 250<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "batch_size = 50\n",
    "\n",
    "iteracoes_epoca = N/batch_size\n",
    "iteracoes_epoca * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisará de 8000/50 = 160 iterações para completar 1 época.<br>\n",
    "Para completar 5 épocas = 160 x 5 = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Exercícios Complementares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 8)\n",
    "\n",
    "As redes neurais artificiais são uma família de métodos conhecidos por conexionistas. Assinale a alternativa mais completa que explica o porquê.\n",
    " \n",
    " <font color='red'>(a) Porque são inspirados por neurônios biológicos, que representam a informação por uma rede de unidades de processamento e o aprendizado pela força de suas conexões</font><br>\n",
    " (b) Porque apenas as redes neurais possuem uma estrutura em que há nós conectados pelos quais passam as informações<br>\n",
    " (c) Porque é possível conectar os neurônios artificiais de qualquer maneira, simulando um cérebro humano<br>\n",
    " (d) Porque são métodos de aprendizado de máquina supervisionados não-paramétricos, muito utilizados em tarefas de classificação e regressão, e que armazenam informações em nós organizados de forma hierárquica, desde sua entrada, conhecida por raiz, até a saída, chamada de folha.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É chamado de método conexionista porque estabelece a força das conexões (vetor w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 9)\n",
    "\n",
    "Defina as sementes aleatórias do numpy para 1 e do tensorflow para 2, depois carregue a base de dados boston housing da biblioteca Keras, conforme código abaixo. \n",
    "\n",
    "O objetivo dessa base de dados é obter a regressão do preço das casas com base em 13 características de entrada. Assim, os valores alvo (target) são escalares, tipicamente entre 10 e 50 (representando os preços em milhares de dólares).\n",
    "\n",
    "Considerando o valor alvo descrito, e que você tem disponíveis as funções de ativação: sigmóide, relu, tangente hiperbólica e softmax, escolha as funções mais adequadas e monte uma arquitetura da rede com 3 camadas ocultas, todas com 32 neurônios.\n",
    "\n",
    "Como deve ficar a arquitetura da rede neural?\n",
    "\n",
    "(a) 4 camadas com 32, 32, 32 e 50 neurônios, 4202 parâmetros e função de ativação relu na camada de saída<br>\n",
    "<font color='red'>(b) 4 camadas com 32, 32, 32 e 1 neurônios, 2593 parâmetros e função de ativação relu na camada de saída</font><br>\n",
    "(c) 5 camadas com 13, 32, 32, 32 e 1 neurônios, 2414 parâmetros e função de ativação sigmóide na camada de saída<br>\n",
    "(d) 4 camadas com 32, 32, 32 e 1 neurônios, 2593 parâmetros e função de ativação sigmóide na camada de saída<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n",
      "65536/57026 [==================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_target, y_target) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,593\n",
      "Trainable params: 2,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### seu codigo\n",
    "model2 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=\"relu\", input_shape=(13,)),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função 'relu' é a única que não comprime os valores de saída (entre 0 e 1, entre -1 e 1 etc) e deve ser usada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 10)\n",
    "\n",
    "Utilizando a base de dados e o modelo de rede neural criado na questão anterior, compile o modelo utilizando uma função de custo de média quadrática (mse), o otimizador SGD e a taxa de aprendizado 0.01. Adicione a métrica `mae` (mean absolute error)\n",
    "\n",
    "Depois, normalize os dados (x) por meio da normalização z-score (calcule média e desvio no conjunto de treinamento apenas).\n",
    "\n",
    "Utilize os dados normalizados para treinar a rede neural por 25 épocas, com batch-size 8. \n",
    "\n",
    "Avalie o modelo treinado nos dados de teste, e reporte as posições 0 e 1 do score resultante, respectivamente relativas ao MSE e MAE calculados. Escolha a opção para a qual o intervalo se enquadre nos valores computados.\n",
    "\n",
    "(a) MSE = (600,630), MAE = (20,25)<br>\n",
    "(b) MSE = (90,110), MAE = (1,8) <br>\n",
    "(c) MSE = (3,9), MAE = (50,100) <br>\n",
    "(d) MSE = (550,570), MAE = (22,24) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 347.9305 - mae: 15.6407 - val_loss: 198.9055 - val_mae: 11.5677\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 128.6384 - mae: 8.2107 - val_loss: 102.1584 - val_mae: 7.3856\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 90.7606 - mae: 6.6279 - val_loss: 87.1860 - val_mae: 6.5934\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 85.5814 - mae: 6.5865 - val_loss: 85.1194 - val_mae: 6.5212\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.9476 - mae: 6.5702 - val_loss: 83.9496 - val_mae: 6.5238\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 0s 994us/step - loss: 84.7818 - mae: 6.6279 - val_loss: 83.7019 - val_mae: 6.5334\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 84.7615 - mae: 6.6271 - val_loss: 83.5028 - val_mae: 6.5466\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 84.8819 - mae: 6.6789 - val_loss: 83.5885 - val_mae: 6.5405\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 84.8257 - mae: 6.6720 - val_loss: 83.6676 - val_mae: 6.5355\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 84.7936 - mae: 6.6513 - val_loss: 83.6424 - val_mae: 6.5371\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 84.7687 - mae: 6.6559 - val_loss: 83.6873 - val_mae: 6.5321\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 84.3184 - mae: 6.6058 - val_loss: 83.4925 - val_mae: 6.5475\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 84.8537 - mae: 6.6869 - val_loss: 83.5922 - val_mae: 6.5403\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 84.7531 - mae: 6.6558 - val_loss: 83.5351 - val_mae: 6.5443\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 84.8888 - mae: 6.6564 - val_loss: 83.5643 - val_mae: 6.5422\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.8475 - mae: 6.6748 - val_loss: 83.7623 - val_mae: 6.5310\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.8846 - mae: 6.6774 - val_loss: 83.9869 - val_mae: 6.5226\n",
      "Epoch 18/25\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.8370 - mae: 6.6246 - val_loss: 83.7680 - val_mae: 6.5307\n",
      "Epoch 19/25\n",
      "51/51 [==============================] - 0s 920us/step - loss: 84.7630 - mae: 6.6675 - val_loss: 83.9641 - val_mae: 6.5234\n",
      "Epoch 20/25\n",
      "51/51 [==============================] - 0s 904us/step - loss: 84.9279 - mae: 6.6551 - val_loss: 83.8437 - val_mae: 6.5278\n",
      "Epoch 21/25\n",
      "51/51 [==============================] - 0s 900us/step - loss: 84.7545 - mae: 6.6540 - val_loss: 83.8701 - val_mae: 6.5268\n",
      "Epoch 22/25\n",
      "51/51 [==============================] - 0s 920us/step - loss: 84.8961 - mae: 6.6694 - val_loss: 83.9024 - val_mae: 6.5256\n",
      "Epoch 23/25\n",
      "51/51 [==============================] - 0s 900us/step - loss: 84.8049 - mae: 6.6206 - val_loss: 83.6970 - val_mae: 6.5339\n",
      "Epoch 24/25\n",
      "51/51 [==============================] - 0s 920us/step - loss: 84.7481 - mae: 6.6690 - val_loss: 83.7827 - val_mae: 6.5285\n",
      "Epoch 25/25\n",
      "51/51 [==============================] - 0s 939us/step - loss: 84.8389 - mae: 6.6594 - val_loss: 83.7920 - val_mae: 6.5198\n"
     ]
    }
   ],
   "source": [
    "# normalizacao z-score\n",
    "# calculamos média e desvio no treinamento e aplicamos em treinamento e target\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "\n",
    "x_target -= mean\n",
    "x_target /= std\n",
    "\n",
    "\n",
    "# compilamos o modelo\n",
    "model2.compile(\n",
    "    optimizer=keras.optimizers.SGD(0.01), loss=\"mse\", metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "batch_size=8\n",
    "epochs=25\n",
    "history2 = model2.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_target, y_target),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83.7920150756836, 6.519824981689453]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model2.evaluate(x_target, y_target, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 83.8\n",
      "MAE: 6.5\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(x_target, y_target, verbose=0)\n",
    "print(\"MSE: %.1f\" % (score[0]))\n",
    "print(\"MAE: %.1f\" % (score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
